{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "add_synth_test_sub_data_results_transfer_learning_approach_0_40.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUsWZbrWIt_L",
        "colab_type": "code",
        "outputId": "2fc5657b-e115-4e05-9279-a5123a58795b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "! pip install seqeval\n",
        "! pip install sklearn_crfsuite\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import nan\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "import keras as k\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#loading train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive//My Drive/entity_train.csv')\n",
        "synth_df=pd.read_csv('/content/drive//My Drive/entity_synth_test.csv')\n",
        "df=pd.concat([df,synth_df]).reset_index(drop=True)\n",
        "\n",
        "df1=df[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1[df1['type']=='entity']  #We take only the entities i.e. removing the text and relation types\n",
        "\n",
        "df1=df1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "#loading test data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dftest=pd.read_csv('/content/drive//My Drive/entity_test.csv')\n",
        "\n",
        "dftest1=dftest[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1[dftest1['type']=='entity']  #We take only the entities i.e. removing the text and relation\n",
        "\n",
        "dftest1=dftest1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "###creating sentence id\n",
        "\n",
        "#for train data\n",
        "\n",
        "index_train=df1.index\n",
        "\n",
        "\n",
        "seq_train=[]\n",
        "seq_train.append(df1['sentence_idx'][index_train[0]])\n",
        "for i in range(1,len(index_train)):\n",
        "  seq_train.append(df1['sentence_idx'][index_train[i]]-df1['sentence_idx'][index_train[i-1]])\n",
        "len(seq_train)\n",
        "\n",
        "\n",
        "neg_ind_train=[]\n",
        "for i in range(len(seq_train)):\n",
        "  if seq_train[i]<0:\n",
        "    seq_train[i]=1\n",
        "    neg_ind_train.append(i)\n",
        "\n",
        "df1=df1.assign(ind_train=seq_train)\n",
        "sen_id=df1['ind_train'].cumsum()\n",
        "df1=df1.assign(sentence_idx=sen_id)\n",
        "df1=df1.drop('ind_train',1)\n",
        "df1=df1.dropna()\n",
        "\n",
        "#creating sentence id for test data\n",
        "\n",
        "index_test=dftest1.index\n",
        "\n",
        "\n",
        "seq_test=[]\n",
        "seq_test.append(dftest1['sentence_idx'][index_test[0]])\n",
        "for i in range(1,len(index_test)):\n",
        "  seq_test.append(dftest1['sentence_idx'][index_test[i]]-dftest1['sentence_idx'][index_test[i-1]])\n",
        "len(seq_test)\n",
        "\n",
        "\n",
        "neg_ind_test=[]\n",
        "for i in range(len(seq_test)):\n",
        "  if seq_test[i]<0:\n",
        "    seq_test[i]=1\n",
        "    neg_ind_test.append(i)\n",
        "\n",
        "dftest1=dftest1.assign(ind_test=seq_test)\n",
        "sen_id=dftest1['ind_test'].cumsum()\n",
        "dftest1=dftest1.assign(sentence_idx=sen_id)\n",
        "dftest1=dftest1.drop('ind_test',1)\n",
        "dftest1=dftest1.dropna()\n",
        "\n",
        "import random\n",
        "random.seed(123)\n",
        "sample01=random.sample(list(dftest1.sentence_idx.unique()),10000)\n",
        "\n",
        "s_ind=[]\n",
        "for i in dftest1.index:\n",
        "  if dftest1.sentence_idx[i] in sample01:\n",
        "    s_ind.append(i)\n",
        "\n",
        "dftest1=dftest1.loc[s_ind]\n",
        "\n",
        "#Split test data into 2 half\n",
        "test_sp1, test_sp2 = train_test_split(dftest1, test_size=0.5,random_state=123)\n",
        "\n",
        "dftest_sp1=test_sp1.sort_index(axis = 0)\t# sort by index labels\n",
        "dfdev1, test_sp = train_test_split(test_sp2, test_size=0.5,random_state=123)\t#Split other half test data into dev and test data\n",
        "dfdev1=dfdev1.sort_index(axis=0)\n",
        "test_sp=test_sp.sort_index(axis=0)\n",
        "dftest1=test_sp\n",
        "\n",
        "#Taking only required tags and the rest renamed as others 'O'\n",
        "tag_req=['diap','fndg','lbpr','lbtr']\n",
        "df2=df1[df1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_train=df2.index\n",
        "\n",
        "for i in df1.index:\n",
        "  if i not in req_train:\n",
        "    df1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in df1.tag[i]:\n",
        "      df1.tag[i]='O'\n",
        "\n",
        "dftest2=dftest1[dftest1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test=dftest2.index\n",
        "\n",
        "for i in dftest1.index:\n",
        "  if i not in req_test:\n",
        "    dftest1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest1.tag[i]:\n",
        "      dftest1.tag[i]='O'\n",
        "\n",
        "dfdev2=dfdev1[dfdev1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_dev=dfdev2.index\n",
        "\n",
        "for i in dfdev1.index:\n",
        "  if i not in req_dev:\n",
        "    dfdev1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dfdev1.tag[i]:\n",
        "      dfdev1.tag[i]='O'\n",
        "\n",
        "dftest_sp2=dftest_sp1[dftest_sp1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test_sp=dftest_sp2.index\n",
        "\n",
        "for i in dftest_sp1.index:\n",
        "  if i not in req_test_sp:\n",
        "    dftest_sp1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest_sp1.tag[i]:\n",
        "      dftest_sp1.tag[i]='O'\n",
        "\n",
        "#BIO-tagging For Train Data\n",
        "temp01=pd.DataFrame(df1.word.str.split().tolist(), index=df1['sentence_idx']).stack()\n",
        "d1 = temp01.index\n",
        "t1 = []\n",
        "for i in range(len(d1)):\n",
        "  if d1[i][1] == 0:\n",
        "    t1.append('B-')\n",
        "  else:\n",
        "    t1.append('I-')\n",
        "temp01 = temp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp01.columns = ['word','sentence_idx']\n",
        "temp01=temp01[['sentence_idx','word']]\n",
        "temp01=temp01.assign(bio_tr=t1)\n",
        "\n",
        "temp02=pd.DataFrame(df1.word.str.split().tolist(), index=df1['tag']).stack()\n",
        "temp02 = temp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp02.columns = ['word','tag']\n",
        "\n",
        "temp01[\"tag\"] = temp01[\"bio_tr\"].astype(str) + temp02[\"tag\"]\n",
        "del temp01['bio_tr']\n",
        "temp01['tag']=temp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "df1=temp01\n",
        "\n",
        "#BIO-tagging For Test Data\n",
        "temp_test01=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['sentence_idx']).stack()\n",
        "d1_test = temp_test01.index\n",
        "t1_test = []\n",
        "for i in range(len(d1_test)):\n",
        "  if d1_test[i][1] == 0:\n",
        "    t1_test.append('B-')\n",
        "  else:\n",
        "    t1_test.append('I-')\n",
        "temp_test01 = temp_test01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test01.columns = ['word','sentence_idx']\n",
        "temp_test01=temp_test01[['sentence_idx','word']]\n",
        "temp_test01=temp_test01.assign(bio_te=t1_test)\n",
        "\n",
        "temp_test02=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['tag']).stack()\n",
        "temp_test02 = temp_test02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test02.columns = ['word','tag']\n",
        "\n",
        "temp_test01[\"tag\"] = temp_test01[\"bio_te\"].astype(str) + temp_test02[\"tag\"]\n",
        "del temp_test01['bio_te']\n",
        "temp_test01['tag']=temp_test01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest1=temp_test01\n",
        "\n",
        "#BIO-tagging For dev Data\n",
        "temp_dev01=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['sentence_idx']).stack()\n",
        "d1_dev = temp_dev01.index\n",
        "t1_dev = []\n",
        "for i in range(len(d1_dev)):\n",
        "  if d1_dev[i][1] == 0:\n",
        "    t1_dev.append('B-')\n",
        "  else:\n",
        "    t1_dev.append('I-')\n",
        "temp_dev01 = temp_dev01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_dev01.columns = ['word','sentence_idx']\n",
        "temp_dev01=temp_dev01[['sentence_idx','word']]\n",
        "temp_dev01=temp_dev01.assign(bio_te=t1_dev)\n",
        "\n",
        "temp_dev02=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['tag']).stack()\n",
        "temp_dev02 = temp_dev02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_dev02.columns = ['word','tag']\n",
        "\n",
        "temp_dev01[\"tag\"] = temp_dev01[\"bio_te\"].astype(str) + temp_dev02[\"tag\"]\n",
        "del temp_dev01['bio_te']\n",
        "temp_dev01['tag']=temp_dev01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dfdev1=temp_dev01\n",
        "\n",
        "#BIO-tagging For test split1 Data\n",
        "temp_test_sp01=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['sentence_idx']).stack()\n",
        "d1_test_sp = temp_test_sp01.index\n",
        "t1_test_sp = []\n",
        "for i in range(len(d1_test_sp)):\n",
        "  if d1_test_sp[i][1] == 0:\n",
        "    t1_test_sp.append('B-')\n",
        "  else:\n",
        "    t1_test_sp.append('I-')\n",
        "temp_test_sp01 = temp_test_sp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp01.columns = ['word','sentence_idx']\n",
        "temp_test_sp01=temp_test_sp01[['sentence_idx','word']]\n",
        "temp_test_sp01=temp_test_sp01.assign(bio_te=t1_test_sp)\n",
        "\n",
        "temp_test_sp02=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['tag']).stack()\n",
        "temp_test_sp02 = temp_test_sp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp02.columns = ['word','tag']\n",
        "\n",
        "temp_test_sp01[\"tag\"] = temp_test_sp01[\"bio_te\"].astype(str) + temp_test_sp02[\"tag\"]\n",
        "del temp_test_sp01['bio_te']\n",
        "temp_test_sp01['tag']=temp_test_sp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest_sp1=temp_test_sp01\n",
        "\n",
        "train=df1\n",
        "test=dftest1\n",
        "dev=dfdev1\n",
        "train2=dftest_sp1\n",
        "\n",
        "#Define Sentence Getter\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "#Sentence getter for train\n",
        "getter_train = SentenceGetter(train)\n",
        "sentences_train = getter_train.sentences\n",
        "\n",
        "#Sentence getter for test\n",
        "getter_test = SentenceGetter(test)\n",
        "sentences_test = getter_test.sentences\n",
        "\n",
        "#Sentence getter for dev\n",
        "getter_dev = SentenceGetter(dev)\n",
        "sentences_dev = getter_dev.sentences\n",
        "\n",
        "#Sentence getter for train2\n",
        "getter_train2 = SentenceGetter(train2)\n",
        "sentences_train2 = getter_train2.sentences\n",
        "\n",
        "##formation of words and tags\n",
        "\n",
        "#for train\n",
        "\n",
        "words_train = list(set(train[\"word\"].values))\n",
        "n_words_train = len(words_train)\n",
        "\n",
        "tags_train = []\n",
        "for tag in set(train[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train.append('unk')\n",
        "    else:\n",
        "        tags_train.append(tag)\n",
        "n_tags_train = len(tags_train)\n",
        "\n",
        "#for test\n",
        "words_test = list(set(test[\"word\"].values))\n",
        "n_words_test = len(words_test)\n",
        "\n",
        "tags_test = []\n",
        "for tag in set(test[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_test.append('unk')\n",
        "    else:\n",
        "        tags_test.append(tag)\n",
        "n_tags_test = len(tags_test)\n",
        "\n",
        "#for dev\n",
        "words_dev = list(set(dev[\"word\"].values))\n",
        "n_words_dev = len(words_dev)\n",
        "\n",
        "tags_dev = []\n",
        "for tag in set(dev[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_dev.append('unk')\n",
        "    else:\n",
        "        tags_dev.append(tag)\n",
        "n_tags_dev = len(tags_dev)\n",
        "\n",
        "#for train2\n",
        "words_train2 = list(set(train2[\"word\"].values))\n",
        "n_words_train2 = len(words_train2)\n",
        "\n",
        "tags_train2 = []\n",
        "for tag in set(train2[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train2.append('unk')\n",
        "    else:\n",
        "        tags_train2.append(tag)\n",
        "n_tags_train2 = len(tags_train2)\n",
        "\n",
        "#taking union of train, dev and test\n",
        "\n",
        "words_all = list(set().union(words_train,words_test,words_dev,words_train2))\n",
        "n_words_all = len(words_all)\n",
        "\n",
        "tags_all = list(set().union(tags_train,tags_test,tags_dev,tags_train2))\n",
        "n_tags_all = len(tags_all)\n",
        "\n",
        "##formation of word2id, tag2id and id2tag\n",
        "\n",
        "#for all union of train and test\n",
        "word2idx_all = {w: i for i, w in enumerate(words_all)}\n",
        "tag2idx_all = {t: i for i, t in enumerate(tags_all)}\n",
        "idx2tag_all = {v: k for k, v in iteritems(tag2idx_all)}\n",
        "\n",
        "maxlen_all = max(max([len(s) for s in sentences_train]),max([len(s) for s in sentences_test]),max([len(s) for s in sentences_dev]),max([len(s) for s in sentences_train2]))\n",
        "\n",
        "##vectorisation\n",
        "\n",
        "#for train\n",
        "\n",
        "maxlen_train = max([len(s) for s in sentences_train])\n",
        "\n",
        "X_train = [[word2idx_all[w[0]] for w in s] for s in sentences_train]\n",
        "X_train = pad_sequences(maxlen=maxlen_all, sequences=X_train, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train = [[tag2idx_all[w[1]] for w in s] for s in sentences_train]\n",
        "y_train = pad_sequences(maxlen=maxlen_all, sequences=y_train, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train = [to_categorical(i, num_classes=n_tags_all) for i in y_train]\n",
        "\n",
        "\n",
        "#for test\n",
        "maxlen_test = max([len(s) for s in sentences_test])\n",
        "\n",
        "X_test = [[word2idx_all[w[0]] for w in s] for s in sentences_test]\n",
        "X_test = pad_sequences(maxlen=maxlen_all, sequences=X_test, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_test = [[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "y_test = pad_sequences(maxlen=maxlen_all, sequences=y_test, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_test = [to_categorical(i, num_classes=n_tags_all) for i in y_test]\n",
        "\n",
        "#for dev\n",
        "maxlen_dev = max([len(s) for s in sentences_dev])\n",
        "\n",
        "X_dev = [[word2idx_all[w[0]] for w in s] for s in sentences_dev]\n",
        "X_dev = pad_sequences(maxlen=maxlen_all, sequences=X_dev, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_dev = [[tag2idx_all[w[1]] for w in s] for s in sentences_dev]\n",
        "y_dev = pad_sequences(maxlen=maxlen_all, sequences=y_dev, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_dev = [to_categorical(i, num_classes=n_tags_all) for i in y_dev]\n",
        "\n",
        "#for train2\n",
        "maxlen_train2 = max([len(s) for s in sentences_train2])\n",
        "\n",
        "X_train2 = [[word2idx_all[w[0]] for w in s] for s in sentences_train2]\n",
        "X_train2 = pad_sequences(maxlen=maxlen_all, sequences=X_train2, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train2 = [[tag2idx_all[w[1]] for w in s] for s in sentences_train2]\n",
        "y_train2 = pad_sequences(maxlen=maxlen_all, sequences=y_train2, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train2 = [to_categorical(i, num_classes=n_tags_all) for i in y_train2]\n",
        "\n",
        "##MODEL\n",
        "\n",
        "input = Input(shape=(max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]),))\n",
        "word_embedding_size = 180\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=n_words_all, output_dim=word_embedding_size, input_length=max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]))(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(n_tags_all, activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(n_tags_all)\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "##FIT MODEL\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Saving the best model only\n",
        "filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-u97trcgt\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-u97trcgt\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=329e51173a11c3f3ed3bc589b6a0b6ea0a9f8831b506d1429bb012c3d4b42649\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f2jbpjls/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18,19,20,24,25,32,33,47,48,49,50,51,52,53,54,60,61,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:149: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 274)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 274, 180)          3473820   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 274, 360)          519840    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 274, 360)          1038240   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 274, 9)            3249      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 274, 9)            189       \n",
            "=================================================================\n",
            "Total params: 5,035,338\n",
            "Trainable params: 5,035,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyGqv96RJLze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76f1e373-d699-4919-d6c2-2eaa1913b19c"
      },
      "source": [
        "# Fit the best model with train data\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=40, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 46502 samples, validate on 5167 samples\n",
            "Epoch 1/40\n",
            "46502/46502 [==============================] - 538s 12ms/step - loss: 0.0752 - crf_viterbi_accuracy: 0.9801 - accuracy: 4.2460e-05 - val_loss: 0.0130 - val_crf_viterbi_accuracy: 0.9975 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99743, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0144 - crf_viterbi_accuracy: 0.9970 - accuracy: 4.2460e-05 - val_loss: 0.0111 - val_crf_viterbi_accuracy: 0.9975 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.99743\n",
            "Epoch 3/40\n",
            "46502/46502 [==============================] - 529s 11ms/step - loss: 0.0117 - crf_viterbi_accuracy: 0.9970 - accuracy: 4.2460e-05 - val_loss: 0.0084 - val_crf_viterbi_accuracy: 0.9979 - val_accuracy: 0.9979\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.99743 to 0.99788, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 4/40\n",
            "46502/46502 [==============================] - 529s 11ms/step - loss: 0.0085 - crf_viterbi_accuracy: 0.9977 - accuracy: 4.2460e-05 - val_loss: 0.0066 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99788 to 0.99830, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0069 - crf_viterbi_accuracy: 0.9980 - accuracy: 4.2460e-05 - val_loss: 0.0057 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99830 to 0.99834, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0058 - crf_viterbi_accuracy: 0.9981 - accuracy: 4.2460e-05 - val_loss: 0.0050 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99834 to 0.99839, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/40\n",
            "46502/46502 [==============================] - 529s 11ms/step - loss: 0.0047 - crf_viterbi_accuracy: 0.9982 - accuracy: 4.2460e-05 - val_loss: 0.0040 - val_crf_viterbi_accuracy: 0.9985 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99839 to 0.99852, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0034 - crf_viterbi_accuracy: 0.9985 - accuracy: 4.2460e-05 - val_loss: 0.0032 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99852 to 0.99862, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 9/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0023 - crf_viterbi_accuracy: 0.9986 - accuracy: 4.2460e-05 - val_loss: 0.0025 - val_crf_viterbi_accuracy: 0.9987 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99862 to 0.99871, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: 0.0015 - crf_viterbi_accuracy: 0.9988 - accuracy: 4.2460e-05 - val_loss: 0.0019 - val_crf_viterbi_accuracy: 0.9989 - val_accuracy: 0.9989\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99871 to 0.99886, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "46502/46502 [==============================] - 528s 11ms/step - loss: 6.9795e-04 - crf_viterbi_accuracy: 0.9990 - accuracy: 4.2460e-05 - val_loss: 0.0014 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99886 to 0.99896, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/40\n",
            "46502/46502 [==============================] - 529s 11ms/step - loss: 2.4585e-05 - crf_viterbi_accuracy: 0.9991 - accuracy: 4.2460e-05 - val_loss: 7.2468e-04 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.99896 to 0.99898, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 13/40\n",
            "46502/46502 [==============================] - 527s 11ms/step - loss: -5.8844e-04 - crf_viterbi_accuracy: 0.9992 - accuracy: 4.2460e-05 - val_loss: 2.2860e-04 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99898 to 0.99900, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: -0.0011 - crf_viterbi_accuracy: 0.9992 - accuracy: 4.2460e-05 - val_loss: -1.6371e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99900 to 0.99906, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 15/40\n",
            "46502/46502 [==============================] - 530s 11ms/step - loss: -0.0017 - crf_viterbi_accuracy: 0.9993 - accuracy: 4.2460e-05 - val_loss: -6.0618e-04 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99906\n",
            "Epoch 16/40\n",
            "46502/46502 [==============================] - 532s 11ms/step - loss: -0.0022 - crf_viterbi_accuracy: 0.9993 - accuracy: 4.2460e-05 - val_loss: -9.2179e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.99906 to 0.99911, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 17/40\n",
            "46502/46502 [==============================] - 534s 11ms/step - loss: -0.0027 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2460e-05 - val_loss: -0.0013 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99911\n",
            "Epoch 18/40\n",
            "46502/46502 [==============================] - 533s 11ms/step - loss: -0.0031 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2460e-05 - val_loss: -0.0017 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.99911 to 0.99911, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 19/40\n",
            "46502/46502 [==============================] - 535s 12ms/step - loss: -0.0035 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2460e-05 - val_loss: -0.0021 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.99911 to 0.99923, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 20/40\n",
            "46502/46502 [==============================] - 534s 11ms/step - loss: -0.0040 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2460e-05 - val_loss: -0.0024 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99923\n",
            "Epoch 21/40\n",
            "46502/46502 [==============================] - 538s 12ms/step - loss: -0.0044 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2460e-05 - val_loss: -0.0028 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99923\n",
            "Epoch 22/40\n",
            "46502/46502 [==============================] - 538s 12ms/step - loss: -0.0048 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2460e-05 - val_loss: -0.0031 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99923\n",
            "Epoch 23/40\n",
            "46502/46502 [==============================] - 535s 11ms/step - loss: -0.0052 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2460e-05 - val_loss: -0.0035 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99923\n",
            "Epoch 24/40\n",
            "46502/46502 [==============================] - 533s 11ms/step - loss: -0.0056 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2460e-05 - val_loss: -0.0038 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99923\n",
            "Epoch 25/40\n",
            "46502/46502 [==============================] - 533s 11ms/step - loss: -0.0060 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0041 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99923\n",
            "Epoch 26/40\n",
            "46502/46502 [==============================] - 534s 11ms/step - loss: -0.0064 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0044 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99923\n",
            "Epoch 27/40\n",
            "46502/46502 [==============================] - 534s 11ms/step - loss: -0.0068 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0047 - val_crf_viterbi_accuracy: 0.9993 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.99923 to 0.99924, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 28/40\n",
            "46502/46502 [==============================] - 532s 11ms/step - loss: -0.0072 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0051 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99924\n",
            "Epoch 29/40\n",
            "46502/46502 [==============================] - 535s 12ms/step - loss: -0.0075 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0054 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99924\n",
            "Epoch 30/40\n",
            "46502/46502 [==============================] - 531s 11ms/step - loss: -0.0079 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2460e-05 - val_loss: -0.0057 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99924\n",
            "Epoch 31/40\n",
            "46502/46502 [==============================] - 535s 11ms/step - loss: -0.0083 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0060 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99924\n",
            "Epoch 32/40\n",
            "46502/46502 [==============================] - 532s 11ms/step - loss: -0.0087 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0064 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99924\n",
            "Epoch 33/40\n",
            "46502/46502 [==============================] - 533s 11ms/step - loss: -0.0090 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0067 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99924\n",
            "Epoch 34/40\n",
            "46502/46502 [==============================] - 536s 12ms/step - loss: -0.0094 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0071 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99924\n",
            "Epoch 35/40\n",
            "46502/46502 [==============================] - 535s 11ms/step - loss: -0.0098 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0073 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99924\n",
            "Epoch 36/40\n",
            "46502/46502 [==============================] - 556s 12ms/step - loss: -0.0101 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0077 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99924\n",
            "Epoch 37/40\n",
            "46502/46502 [==============================] - 545s 12ms/step - loss: -0.0105 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0080 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99924\n",
            "Epoch 38/40\n",
            "46502/46502 [==============================] - 539s 12ms/step - loss: -0.0108 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0084 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99924\n",
            "Epoch 39/40\n",
            "46502/46502 [==============================] - 538s 12ms/step - loss: -0.0112 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0086 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99924\n",
            "Epoch 40/40\n",
            "46502/46502 [==============================] - 538s 12ms/step - loss: -0.0116 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2460e-05 - val_loss: -0.0089 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvuyOt8QJnMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eacc9d1e-60b2-443b-90da-099689995641"
      },
      "source": [
        "# Fit the best model with train2 data\n",
        "history = model.fit(X_train2, np.array(y_train2), batch_size=256, epochs=40, validation_data=(X_dev, np.array(y_dev)), verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8577 samples, validate on 6368 samples\n",
            "Epoch 1/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0095 - crf_viterbi_accuracy: 0.9992 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00001: val_accuracy improved from 0.99924 to 0.99956, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0106 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.2340e-05 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.99956 to 0.99962, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 3/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0111 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2340e-05 - val_loss: -0.0113 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.99962\n",
            "Epoch 4/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0114 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2340e-05 - val_loss: -0.0113 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.99962\n",
            "Epoch 5/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0116 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2340e-05 - val_loss: -0.0114 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99962 to 0.99963, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0118 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2340e-05 - val_loss: -0.0115 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99963\n",
            "Epoch 7/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0119 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0115 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99963 to 0.99963, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0121 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0115 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99963\n",
            "Epoch 9/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0122 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99963 to 0.99963, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0124 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99963\n",
            "Epoch 11/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0125 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99963\n",
            "Epoch 12/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0126 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0117 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99963\n",
            "Epoch 13/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99963 to 0.99964, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0128 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99964\n",
            "Epoch 15/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0128 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99964\n",
            "Epoch 16/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0130 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99964\n",
            "Epoch 17/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0130 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99964\n",
            "Epoch 18/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0131 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99964\n",
            "Epoch 19/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0132 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99964\n",
            "Epoch 20/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0133 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99964\n",
            "Epoch 21/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99964\n",
            "Epoch 22/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99964\n",
            "Epoch 23/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0135 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0121 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99964\n",
            "Epoch 24/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0136 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0121 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99964\n",
            "Epoch 25/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0136 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0122 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99964\n",
            "Epoch 26/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0137 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0123 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99964\n",
            "Epoch 27/40\n",
            "8577/8577 [==============================] - 107s 13ms/step - loss: -0.0138 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0123 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99964\n",
            "Epoch 28/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0139 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0123 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99964\n",
            "Epoch 29/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0139 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0123 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99964\n",
            "Epoch 30/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0140 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0124 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99964\n",
            "Epoch 31/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0141 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0124 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99964\n",
            "Epoch 32/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0141 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0125 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99964\n",
            "Epoch 33/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0142 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0125 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99964\n",
            "Epoch 34/40\n",
            "8577/8577 [==============================] - 107s 12ms/step - loss: -0.0142 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0125 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99964\n",
            "Epoch 35/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0143 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0126 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99964\n",
            "Epoch 36/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0144 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0126 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99964\n",
            "Epoch 37/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0145 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0127 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99964\n",
            "Epoch 38/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0145 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0128 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99964\n",
            "Epoch 39/40\n",
            "8577/8577 [==============================] - 109s 13ms/step - loss: -0.0146 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0128 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99964\n",
            "Epoch 40/40\n",
            "8577/8577 [==============================] - 108s 13ms/step - loss: -0.0147 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0129 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC8zuFp8JnJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "896a08cb-622e-45a8-b3f9-631761202f5b"
      },
      "source": [
        "####PLOTS of loss and accuracy\n",
        "# Plot the graph \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "####FIT with the TEST data\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag_all[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "test_pred = model.predict(X_test, verbose=1)   \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(y_test)\n",
        "\n",
        "#####REPORT of the fit\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "print(report)\n",
        "\n",
        "###Rest\n",
        "TP = {}\n",
        "TN = {}\n",
        "FP = {}\n",
        "FN = {}\n",
        "for tag in tag2idx_all.keys():\n",
        "    TP[tag] = 0\n",
        "    TN[tag] = 0    \n",
        "    FP[tag] = 0    \n",
        "    FN[tag] = 0    \n",
        "\n",
        "def accumulate_score_by_tag(gt, pred):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] +=1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "for i, sentence in enumerate(X_test):\n",
        "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "    gt = np.argmax(y_test[0], axis=-1)\n",
        "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
        "        accumulate_score_by_tag(idx2tag_all[gt[idx]],tags_all[pred])\n",
        "\n",
        "for tag in tag2idx_all.keys():\n",
        "    print(f'tag:{tag}')    \n",
        "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
        "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6339/6339 [==============================] - 58s 9ms/step\n",
            "F1-score: 85.0%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-diap       0.89      0.87      0.88       278\n",
            "      B-fndg       0.87      0.86      0.87       925\n",
            "      B-lbpr       0.93      0.86      0.90       130\n",
            "      B-lbtr       0.80      0.67      0.73        12\n",
            "      I-diap       0.86      0.87      0.86       138\n",
            "      I-fndg       0.85      0.83      0.84       844\n",
            "      I-lbpr       0.83      0.77      0.80        62\n",
            "      I-lbtr       0.75      0.38      0.50         8\n",
            "           O       1.00      1.00      1.00   1734489\n",
            "\n",
            "    accuracy                           1.00   1736886\n",
            "   macro avg       0.86      0.79      0.82   1736886\n",
            "weighted avg       1.00      1.00      1.00   1736886\n",
            "\n",
            "tag:B-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:O\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:   1730547\n",
            "tag:I-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:      6339\n",
            "tag:B-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI9_YWV2JnHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "train.to_csv('train.csv')\n",
        "dev.to_csv('dev.csv')\n",
        "test.to_csv('test.csv')\n",
        "train2.to_csv('train2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz8Qe9vsJnDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_unstructured=pd.DataFrame({'Test Tag':test_labels,'Predicted Tag':pred_labels})\n",
        "result_unstructured.to_csv('result_unstructured.csv')\n",
        "\n",
        "test_tag_temp01=[[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "test_tag_ind01=[]\n",
        "for i in range(len(test_tag_temp01)):\n",
        "  test_tag_ind01.append(len(test_tag_temp01[i]))\n",
        "\n",
        "predicted_tag_temp01=[]\n",
        "for i in range(len(pred_labels)):\n",
        "  predicted_tag_temp01.extend(pred_labels[i][:test_tag_ind01[i]])\n",
        "\n",
        "result=test.assign(predicted_tag=predicted_tag_temp01)\n",
        "result.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEXiRhb8JnAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}