{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_sub_data_results_transfer_learning_approach_0_40.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrObco6_PAI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c808f8c-d534-42a4-e850-193e2b32ad73"
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "! pip install seqeval\n",
        "! pip install sklearn_crfsuite\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import nan\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "import keras as k\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#loading train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive//My Drive/entity_train.csv')\n",
        "\n",
        "df1=df[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1[df1['type']=='entity']  #We take only the entities i.e. removing the text and relation types\n",
        "\n",
        "df1=df1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "#loading test data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dftest=pd.read_csv('/content/drive//My Drive/entity_test.csv')\n",
        "\n",
        "dftest1=dftest[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1[dftest1['type']=='entity']  #We take only the entities i.e. removing the text and relation\n",
        "\n",
        "dftest1=dftest1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "###creating sentence id\n",
        "\n",
        "#for train data\n",
        "\n",
        "index_train=df1.index\n",
        "\n",
        "\n",
        "seq_train=[]\n",
        "seq_train.append(df1['sentence_idx'][index_train[0]])\n",
        "for i in range(1,len(index_train)):\n",
        "  seq_train.append(df1['sentence_idx'][index_train[i]]-df1['sentence_idx'][index_train[i-1]])\n",
        "len(seq_train)\n",
        "\n",
        "\n",
        "neg_ind_train=[]\n",
        "for i in range(len(seq_train)):\n",
        "  if seq_train[i]<0:\n",
        "    seq_train[i]=1\n",
        "    neg_ind_train.append(i)\n",
        "\n",
        "df1=df1.assign(ind_train=seq_train)\n",
        "sen_id=df1['ind_train'].cumsum()\n",
        "df1=df1.assign(sentence_idx=sen_id)\n",
        "df1=df1.drop('ind_train',1)\n",
        "df1=df1.dropna()\n",
        "\n",
        "#creating sentence id for test data\n",
        "\n",
        "index_test=dftest1.index\n",
        "\n",
        "\n",
        "seq_test=[]\n",
        "seq_test.append(dftest1['sentence_idx'][index_test[0]])\n",
        "for i in range(1,len(index_test)):\n",
        "  seq_test.append(dftest1['sentence_idx'][index_test[i]]-dftest1['sentence_idx'][index_test[i-1]])\n",
        "len(seq_test)\n",
        "\n",
        "\n",
        "neg_ind_test=[]\n",
        "for i in range(len(seq_test)):\n",
        "  if seq_test[i]<0:\n",
        "    seq_test[i]=1\n",
        "    neg_ind_test.append(i)\n",
        "\n",
        "dftest1=dftest1.assign(ind_test=seq_test)\n",
        "sen_id=dftest1['ind_test'].cumsum()\n",
        "dftest1=dftest1.assign(sentence_idx=sen_id)\n",
        "dftest1=dftest1.drop('ind_test',1)\n",
        "dftest1=dftest1.dropna()\n",
        "\n",
        "import random\n",
        "random.seed(123)\n",
        "sample01=random.sample(list(dftest1.sentence_idx.unique()),10000)\n",
        "\n",
        "s_ind=[]\n",
        "for i in dftest1.index:\n",
        "  if dftest1.sentence_idx[i] in sample01:\n",
        "    s_ind.append(i)\n",
        "\n",
        "dftest1=dftest1.loc[s_ind]\n",
        "\n",
        "#Split test data into 2 half\n",
        "test_sp1, test_sp2 = train_test_split(dftest1, test_size=0.5,random_state=123)\n",
        "\n",
        "dftest_sp1=test_sp1.sort_index(axis = 0)\t# sort by index labels\n",
        "dfdev1, test_sp = train_test_split(test_sp2, test_size=0.5,random_state=123)\t#Split other half test data into dev and test data\n",
        "dfdev1=dfdev1.sort_index(axis=0)\n",
        "test_sp=test_sp.sort_index(axis=0)\n",
        "dftest1=test_sp\n",
        "\n",
        "#Taking only required tags and the rest renamed as others 'O'\n",
        "tag_req=['diap','fndg','lbpr','lbtr']\n",
        "df2=df1[df1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_train=df2.index\n",
        "\n",
        "for i in df1.index:\n",
        "  if i not in req_train:\n",
        "    df1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in df1.tag[i]:\n",
        "      df1.tag[i]='O'\n",
        "\n",
        "dftest2=dftest1[dftest1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test=dftest2.index\n",
        "\n",
        "for i in dftest1.index:\n",
        "  if i not in req_test:\n",
        "    dftest1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest1.tag[i]:\n",
        "      dftest1.tag[i]='O'\n",
        "\n",
        "dfdev2=dfdev1[dfdev1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_dev=dfdev2.index\n",
        "\n",
        "for i in dfdev1.index:\n",
        "  if i not in req_dev:\n",
        "    dfdev1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dfdev1.tag[i]:\n",
        "      dfdev1.tag[i]='O'\n",
        "\n",
        "dftest_sp2=dftest_sp1[dftest_sp1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test_sp=dftest_sp2.index\n",
        "\n",
        "for i in dftest_sp1.index:\n",
        "  if i not in req_test_sp:\n",
        "    dftest_sp1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest_sp1.tag[i]:\n",
        "      dftest_sp1.tag[i]='O'\n",
        "\n",
        "#BIO-tagging For Train Data\n",
        "temp01=pd.DataFrame(df1.word.str.split().tolist(), index=df1['sentence_idx']).stack()\n",
        "d1 = temp01.index\n",
        "t1 = []\n",
        "for i in range(len(d1)):\n",
        "  if d1[i][1] == 0:\n",
        "    t1.append('B-')\n",
        "  else:\n",
        "    t1.append('I-')\n",
        "temp01 = temp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp01.columns = ['word','sentence_idx']\n",
        "temp01=temp01[['sentence_idx','word']]\n",
        "temp01=temp01.assign(bio_tr=t1)\n",
        "\n",
        "temp02=pd.DataFrame(df1.word.str.split().tolist(), index=df1['tag']).stack()\n",
        "temp02 = temp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp02.columns = ['word','tag']\n",
        "\n",
        "temp01[\"tag\"] = temp01[\"bio_tr\"].astype(str) + temp02[\"tag\"]\n",
        "del temp01['bio_tr']\n",
        "temp01['tag']=temp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "df1=temp01\n",
        "\n",
        "#BIO-tagging For Test Data\n",
        "temp_test01=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['sentence_idx']).stack()\n",
        "d1_test = temp_test01.index\n",
        "t1_test = []\n",
        "for i in range(len(d1_test)):\n",
        "  if d1_test[i][1] == 0:\n",
        "    t1_test.append('B-')\n",
        "  else:\n",
        "    t1_test.append('I-')\n",
        "temp_test01 = temp_test01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test01.columns = ['word','sentence_idx']\n",
        "temp_test01=temp_test01[['sentence_idx','word']]\n",
        "temp_test01=temp_test01.assign(bio_te=t1_test)\n",
        "\n",
        "temp_test02=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['tag']).stack()\n",
        "temp_test02 = temp_test02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test02.columns = ['word','tag']\n",
        "\n",
        "temp_test01[\"tag\"] = temp_test01[\"bio_te\"].astype(str) + temp_test02[\"tag\"]\n",
        "del temp_test01['bio_te']\n",
        "temp_test01['tag']=temp_test01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest1=temp_test01\n",
        "\n",
        "#BIO-tagging For dev Data\n",
        "temp_dev01=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['sentence_idx']).stack()\n",
        "d1_dev = temp_dev01.index\n",
        "t1_dev = []\n",
        "for i in range(len(d1_dev)):\n",
        "  if d1_dev[i][1] == 0:\n",
        "    t1_dev.append('B-')\n",
        "  else:\n",
        "    t1_dev.append('I-')\n",
        "temp_dev01 = temp_dev01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_dev01.columns = ['word','sentence_idx']\n",
        "temp_dev01=temp_dev01[['sentence_idx','word']]\n",
        "temp_dev01=temp_dev01.assign(bio_te=t1_dev)\n",
        "\n",
        "temp_dev02=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['tag']).stack()\n",
        "temp_dev02 = temp_dev02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_dev02.columns = ['word','tag']\n",
        "\n",
        "temp_dev01[\"tag\"] = temp_dev01[\"bio_te\"].astype(str) + temp_dev02[\"tag\"]\n",
        "del temp_dev01['bio_te']\n",
        "temp_dev01['tag']=temp_dev01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dfdev1=temp_dev01\n",
        "\n",
        "#BIO-tagging For test split1 Data\n",
        "temp_test_sp01=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['sentence_idx']).stack()\n",
        "d1_test_sp = temp_test_sp01.index\n",
        "t1_test_sp = []\n",
        "for i in range(len(d1_test_sp)):\n",
        "  if d1_test_sp[i][1] == 0:\n",
        "    t1_test_sp.append('B-')\n",
        "  else:\n",
        "    t1_test_sp.append('I-')\n",
        "temp_test_sp01 = temp_test_sp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp01.columns = ['word','sentence_idx']\n",
        "temp_test_sp01=temp_test_sp01[['sentence_idx','word']]\n",
        "temp_test_sp01=temp_test_sp01.assign(bio_te=t1_test_sp)\n",
        "\n",
        "temp_test_sp02=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['tag']).stack()\n",
        "temp_test_sp02 = temp_test_sp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp02.columns = ['word','tag']\n",
        "\n",
        "temp_test_sp01[\"tag\"] = temp_test_sp01[\"bio_te\"].astype(str) + temp_test_sp02[\"tag\"]\n",
        "del temp_test_sp01['bio_te']\n",
        "temp_test_sp01['tag']=temp_test_sp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest_sp1=temp_test_sp01\n",
        "\n",
        "train=df1\n",
        "test=dftest1\n",
        "dev=dfdev1\n",
        "train2=dftest_sp1\n",
        "\n",
        "#Define Sentence Getter\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "#Sentence getter for train\n",
        "getter_train = SentenceGetter(train)\n",
        "sentences_train = getter_train.sentences\n",
        "\n",
        "#Sentence getter for test\n",
        "getter_test = SentenceGetter(test)\n",
        "sentences_test = getter_test.sentences\n",
        "\n",
        "#Sentence getter for dev\n",
        "getter_dev = SentenceGetter(dev)\n",
        "sentences_dev = getter_dev.sentences\n",
        "\n",
        "#Sentence getter for train2\n",
        "getter_train2 = SentenceGetter(train2)\n",
        "sentences_train2 = getter_train2.sentences\n",
        "\n",
        "##formation of words and tags\n",
        "\n",
        "#for train\n",
        "\n",
        "words_train = list(set(train[\"word\"].values))\n",
        "n_words_train = len(words_train)\n",
        "\n",
        "tags_train = []\n",
        "for tag in set(train[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train.append('unk')\n",
        "    else:\n",
        "        tags_train.append(tag)\n",
        "n_tags_train = len(tags_train)\n",
        "\n",
        "#for test\n",
        "words_test = list(set(test[\"word\"].values))\n",
        "n_words_test = len(words_test)\n",
        "\n",
        "tags_test = []\n",
        "for tag in set(test[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_test.append('unk')\n",
        "    else:\n",
        "        tags_test.append(tag)\n",
        "n_tags_test = len(tags_test)\n",
        "\n",
        "#for dev\n",
        "words_dev = list(set(dev[\"word\"].values))\n",
        "n_words_dev = len(words_dev)\n",
        "\n",
        "tags_dev = []\n",
        "for tag in set(dev[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_dev.append('unk')\n",
        "    else:\n",
        "        tags_dev.append(tag)\n",
        "n_tags_dev = len(tags_dev)\n",
        "\n",
        "#for train2\n",
        "words_train2 = list(set(train2[\"word\"].values))\n",
        "n_words_train2 = len(words_train2)\n",
        "\n",
        "tags_train2 = []\n",
        "for tag in set(train2[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train2.append('unk')\n",
        "    else:\n",
        "        tags_train2.append(tag)\n",
        "n_tags_train2 = len(tags_train2)\n",
        "\n",
        "#taking union of train, dev and test\n",
        "\n",
        "words_all = list(set().union(words_train,words_test,words_dev,words_train2))\n",
        "n_words_all = len(words_all)\n",
        "\n",
        "tags_all = list(set().union(tags_train,tags_test,tags_dev,tags_train2))\n",
        "n_tags_all = len(tags_all)\n",
        "\n",
        "##formation of word2id, tag2id and id2tag\n",
        "\n",
        "#for all union of train and test\n",
        "word2idx_all = {w: i for i, w in enumerate(words_all)}\n",
        "tag2idx_all = {t: i for i, t in enumerate(tags_all)}\n",
        "idx2tag_all = {v: k for k, v in iteritems(tag2idx_all)}\n",
        "\n",
        "maxlen_all = max(max([len(s) for s in sentences_train]),max([len(s) for s in sentences_test]),max([len(s) for s in sentences_dev]),max([len(s) for s in sentences_train2]))\n",
        "\n",
        "##vectorisation\n",
        "\n",
        "#for train\n",
        "\n",
        "maxlen_train = max([len(s) for s in sentences_train])\n",
        "\n",
        "X_train = [[word2idx_all[w[0]] for w in s] for s in sentences_train]\n",
        "X_train = pad_sequences(maxlen=maxlen_all, sequences=X_train, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train = [[tag2idx_all[w[1]] for w in s] for s in sentences_train]\n",
        "y_train = pad_sequences(maxlen=maxlen_all, sequences=y_train, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train = [to_categorical(i, num_classes=n_tags_all) for i in y_train]\n",
        "\n",
        "\n",
        "#for test\n",
        "maxlen_test = max([len(s) for s in sentences_test])\n",
        "\n",
        "X_test = [[word2idx_all[w[0]] for w in s] for s in sentences_test]\n",
        "X_test = pad_sequences(maxlen=maxlen_all, sequences=X_test, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_test = [[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "y_test = pad_sequences(maxlen=maxlen_all, sequences=y_test, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_test = [to_categorical(i, num_classes=n_tags_all) for i in y_test]\n",
        "\n",
        "#for dev\n",
        "maxlen_dev = max([len(s) for s in sentences_dev])\n",
        "\n",
        "X_dev = [[word2idx_all[w[0]] for w in s] for s in sentences_dev]\n",
        "X_dev = pad_sequences(maxlen=maxlen_all, sequences=X_dev, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_dev = [[tag2idx_all[w[1]] for w in s] for s in sentences_dev]\n",
        "y_dev = pad_sequences(maxlen=maxlen_all, sequences=y_dev, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_dev = [to_categorical(i, num_classes=n_tags_all) for i in y_dev]\n",
        "\n",
        "#for train2\n",
        "maxlen_train2 = max([len(s) for s in sentences_train2])\n",
        "\n",
        "X_train2 = [[word2idx_all[w[0]] for w in s] for s in sentences_train2]\n",
        "X_train2 = pad_sequences(maxlen=maxlen_all, sequences=X_train2, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train2 = [[tag2idx_all[w[1]] for w in s] for s in sentences_train2]\n",
        "y_train2 = pad_sequences(maxlen=maxlen_all, sequences=y_train2, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train2 = [to_categorical(i, num_classes=n_tags_all) for i in y_train2]\n",
        "\n",
        "##MODEL\n",
        "\n",
        "input = Input(shape=(max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]),))\n",
        "word_embedding_size = 180\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=n_words_all, output_dim=word_embedding_size, input_length=max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]))(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(n_tags_all, activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(n_tags_all)\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "##FIT MODEL\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Saving the best model only\n",
        "filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-906kcmm3\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-906kcmm3\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=55ddbe901a581daf387e7601b246380aa5edd99c7df08982049045aa458decf6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wp2jw5h_/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=e593117960f12f5b419fe093d26db86170e2f1932705344728df697544ccf7e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18,19,20,24,25,32,33,47,48,49,50,51,52,53,54,60,61,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 274)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 274, 180)          3295080   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 274, 360)          519840    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 274, 360)          1038240   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 274, 9)            3249      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 274, 9)            189       \n",
            "=================================================================\n",
            "Total params: 4,856,598\n",
            "Trainable params: 4,856,598\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59M1UjmJPMx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08a7acd8-a2f6-4815-9700-607b1ad5eb40"
      },
      "source": [
        "# Fit the best model with train data\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=40, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44782 samples, validate on 4976 samples\n",
            "Epoch 1/40\n",
            "44782/44782 [==============================] - 538s 12ms/step - loss: 0.0640 - crf_viterbi_accuracy: 0.9855 - accuracy: 4.2297e-05 - val_loss: 0.0199 - val_crf_viterbi_accuracy: 0.9968 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99686, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "44782/44782 [==============================] - 536s 12ms/step - loss: 0.0177 - crf_viterbi_accuracy: 0.9970 - accuracy: 4.2297e-05 - val_loss: 0.0159 - val_crf_viterbi_accuracy: 0.9968 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.99686\n",
            "Epoch 3/40\n",
            "44782/44782 [==============================] - 531s 12ms/step - loss: 0.0134 - crf_viterbi_accuracy: 0.9970 - accuracy: 4.2297e-05 - val_loss: 0.0108 - val_crf_viterbi_accuracy: 0.9969 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.99686 to 0.99689, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 4/40\n",
            "44782/44782 [==============================] - 535s 12ms/step - loss: 0.0097 - crf_viterbi_accuracy: 0.9972 - accuracy: 4.2297e-05 - val_loss: 0.0089 - val_crf_viterbi_accuracy: 0.9973 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99689 to 0.99737, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "44782/44782 [==============================] - 531s 12ms/step - loss: 0.0081 - crf_viterbi_accuracy: 0.9975 - accuracy: 4.2297e-05 - val_loss: 0.0076 - val_crf_viterbi_accuracy: 0.9975 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99737 to 0.99757, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/40\n",
            "44782/44782 [==============================] - 538s 12ms/step - loss: 0.0068 - crf_viterbi_accuracy: 0.9977 - accuracy: 4.2297e-05 - val_loss: 0.0066 - val_crf_viterbi_accuracy: 0.9979 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99757 to 0.99797, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/40\n",
            "44782/44782 [==============================] - 534s 12ms/step - loss: 0.0057 - crf_viterbi_accuracy: 0.9980 - accuracy: 4.2297e-05 - val_loss: 0.0058 - val_crf_viterbi_accuracy: 0.9980 - val_accuracy: 0.9981\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99797 to 0.99807, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "44782/44782 [==============================] - 537s 12ms/step - loss: 0.0047 - crf_viterbi_accuracy: 0.9982 - accuracy: 4.2297e-05 - val_loss: 0.0048 - val_crf_viterbi_accuracy: 0.9982 - val_accuracy: 0.9982\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99807 to 0.99821, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 9/40\n",
            "44782/44782 [==============================] - 549s 12ms/step - loss: 0.0037 - crf_viterbi_accuracy: 0.9983 - accuracy: 4.2297e-05 - val_loss: 0.0039 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99821 to 0.99831, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "44782/44782 [==============================] - 567s 13ms/step - loss: 0.0028 - crf_viterbi_accuracy: 0.9985 - accuracy: 4.2297e-05 - val_loss: 0.0033 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99831 to 0.99833, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "44782/44782 [==============================] - 535s 12ms/step - loss: 0.0021 - crf_viterbi_accuracy: 0.9985 - accuracy: 4.2297e-05 - val_loss: 0.0028 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99833 to 0.99835, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/40\n",
            "44782/44782 [==============================] - 540s 12ms/step - loss: 0.0015 - crf_viterbi_accuracy: 0.9986 - accuracy: 4.2297e-05 - val_loss: 0.0023 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.99835 to 0.99837, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 13/40\n",
            "44782/44782 [==============================] - 538s 12ms/step - loss: 9.4802e-04 - crf_viterbi_accuracy: 0.9986 - accuracy: 4.2297e-05 - val_loss: 0.0018 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99837 to 0.99842, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/40\n",
            "44782/44782 [==============================] - 546s 12ms/step - loss: 3.4796e-04 - crf_viterbi_accuracy: 0.9987 - accuracy: 4.2297e-05 - val_loss: 0.0013 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99842 to 0.99843, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 15/40\n",
            "44782/44782 [==============================] - 553s 12ms/step - loss: -2.7330e-04 - crf_viterbi_accuracy: 0.9988 - accuracy: 4.2297e-05 - val_loss: 7.9382e-04 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.99843 to 0.99862, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 16/40\n",
            "44782/44782 [==============================] - 553s 12ms/step - loss: -0.0011 - crf_viterbi_accuracy: 0.9990 - accuracy: 4.2297e-05 - val_loss: 7.0412e-05 - val_crf_viterbi_accuracy: 0.9988 - val_accuracy: 0.9988\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.99862 to 0.99885, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 17/40\n",
            "44782/44782 [==============================] - 550s 12ms/step - loss: -0.0018 - crf_viterbi_accuracy: 0.9992 - accuracy: 4.2297e-05 - val_loss: -4.9735e-04 - val_crf_viterbi_accuracy: 0.9989 - val_accuracy: 0.9989\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.99885 to 0.99893, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 18/40\n",
            "44782/44782 [==============================] - 552s 12ms/step - loss: -0.0024 - crf_viterbi_accuracy: 0.9993 - accuracy: 4.2297e-05 - val_loss: -9.9061e-04 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.99893 to 0.99899, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 19/40\n",
            "44782/44782 [==============================] - 547s 12ms/step - loss: -0.0029 - crf_viterbi_accuracy: 0.9993 - accuracy: 4.2297e-05 - val_loss: -0.0015 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.99899 to 0.99903, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 20/40\n",
            "44782/44782 [==============================] - 547s 12ms/step - loss: -0.0034 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2297e-05 - val_loss: -0.0020 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.99903 to 0.99909, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 21/40\n",
            "44782/44782 [==============================] - 549s 12ms/step - loss: -0.0039 - crf_viterbi_accuracy: 0.9994 - accuracy: 4.2297e-05 - val_loss: -0.0022 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.99909 to 0.99912, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 22/40\n",
            "44782/44782 [==============================] - 548s 12ms/step - loss: -0.0043 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2297e-05 - val_loss: -0.0027 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.99912 to 0.99914, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 23/40\n",
            "44782/44782 [==============================] - 544s 12ms/step - loss: -0.0047 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2297e-05 - val_loss: -0.0031 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99914\n",
            "Epoch 24/40\n",
            "44782/44782 [==============================] - 546s 12ms/step - loss: -0.0052 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2297e-05 - val_loss: -0.0034 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.99914 to 0.99916, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 25/40\n",
            "44782/44782 [==============================] - 551s 12ms/step - loss: -0.0056 - crf_viterbi_accuracy: 0.9995 - accuracy: 4.2297e-05 - val_loss: -0.0037 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99916\n",
            "Epoch 26/40\n",
            "44782/44782 [==============================] - 552s 12ms/step - loss: -0.0060 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2297e-05 - val_loss: -0.0042 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99916\n",
            "Epoch 27/40\n",
            "44782/44782 [==============================] - 541s 12ms/step - loss: -0.0064 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2297e-05 - val_loss: -0.0044 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99916\n",
            "Epoch 28/40\n",
            "44782/44782 [==============================] - 540s 12ms/step - loss: -0.0068 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2297e-05 - val_loss: -0.0048 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99916\n",
            "Epoch 29/40\n",
            "44782/44782 [==============================] - 533s 12ms/step - loss: -0.0071 - crf_viterbi_accuracy: 0.9996 - accuracy: 4.2297e-05 - val_loss: -0.0052 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.99916 to 0.99919, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 30/40\n",
            "44782/44782 [==============================] - 537s 12ms/step - loss: -0.0075 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0056 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99919\n",
            "Epoch 31/40\n",
            "44782/44782 [==============================] - 533s 12ms/step - loss: -0.0079 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0057 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99919\n",
            "Epoch 32/40\n",
            "44782/44782 [==============================] - 543s 12ms/step - loss: -0.0083 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0062 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99919\n",
            "Epoch 33/40\n",
            "44782/44782 [==============================] - 540s 12ms/step - loss: -0.0086 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0064 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.99919 to 0.99920, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 34/40\n",
            "44782/44782 [==============================] - 540s 12ms/step - loss: -0.0090 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0068 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99920\n",
            "Epoch 35/40\n",
            "44782/44782 [==============================] - 537s 12ms/step - loss: -0.0093 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0071 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99920\n",
            "Epoch 36/40\n",
            "44782/44782 [==============================] - 526s 12ms/step - loss: -0.0097 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0073 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99920\n",
            "Epoch 37/40\n",
            "44782/44782 [==============================] - 533s 12ms/step - loss: -0.0101 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0077 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99920\n",
            "Epoch 38/40\n",
            "44782/44782 [==============================] - 532s 12ms/step - loss: -0.0104 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0081 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99920\n",
            "Epoch 39/40\n",
            "44782/44782 [==============================] - 541s 12ms/step - loss: -0.0107 - crf_viterbi_accuracy: 0.9997 - accuracy: 4.2297e-05 - val_loss: -0.0084 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99920\n",
            "Epoch 40/40\n",
            "44782/44782 [==============================] - 543s 12ms/step - loss: -0.0111 - crf_viterbi_accuracy: 0.9998 - accuracy: 4.2297e-05 - val_loss: -0.0087 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mv1L5W8PQIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8ffd2de-9bea-47e2-926c-50bd8a36fd25"
      },
      "source": [
        "# Fit the best model with train2 data\n",
        "history = model.fit(X_train2, np.array(y_train2), batch_size=256, epochs=40, validation_data=(X_dev, np.array(y_dev)), verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8577 samples, validate on 6368 samples\n",
            "Epoch 1/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0089 - crf_viterbi_accuracy: 0.9992 - accuracy: 1.2340e-05 - val_loss: -0.0106 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00001: val_accuracy improved from 0.99920 to 0.99959, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0101 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.2340e-05 - val_loss: -0.0106 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.99959 to 0.99961, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 3/40\n",
            "8577/8577 [==============================] - 112s 13ms/step - loss: -0.0105 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2340e-05 - val_loss: -0.0108 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.99961\n",
            "Epoch 4/40\n",
            "8577/8577 [==============================] - 113s 13ms/step - loss: -0.0108 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2340e-05 - val_loss: -0.0109 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99961 to 0.99962, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0111 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2340e-05 - val_loss: -0.0109 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.99962\n",
            "Epoch 6/40\n",
            "8577/8577 [==============================] - 113s 13ms/step - loss: -0.0113 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0109 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99962\n",
            "Epoch 7/40\n",
            "8577/8577 [==============================] - 116s 13ms/step - loss: -0.0115 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0110 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99962\n",
            "Epoch 8/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0116 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0109 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99962\n",
            "Epoch 9/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0118 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99962\n",
            "Epoch 10/40\n",
            "8577/8577 [==============================] - 115s 13ms/step - loss: -0.0119 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0110 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99962 to 0.99963, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "8577/8577 [==============================] - 113s 13ms/step - loss: -0.0120 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99963\n",
            "Epoch 12/40\n",
            "8577/8577 [==============================] - 112s 13ms/step - loss: -0.0121 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99963\n",
            "Epoch 13/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0122 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99963\n",
            "Epoch 14/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0123 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99963\n",
            "Epoch 15/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0124 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99963\n",
            "Epoch 16/40\n",
            "8577/8577 [==============================] - 116s 13ms/step - loss: -0.0125 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99963\n",
            "Epoch 17/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0126 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99963\n",
            "Epoch 18/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99963\n",
            "Epoch 19/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99963\n",
            "Epoch 20/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0128 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0113 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99963\n",
            "Epoch 21/40\n",
            "8577/8577 [==============================] - 116s 13ms/step - loss: -0.0129 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0114 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99963\n",
            "Epoch 22/40\n",
            "8577/8577 [==============================] - 114s 13ms/step - loss: -0.0130 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0114 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99963\n",
            "Epoch 23/40\n",
            "8577/8577 [==============================] - 112s 13ms/step - loss: -0.0130 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0115 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99963\n",
            "Epoch 24/40\n",
            "8577/8577 [==============================] - 113s 13ms/step - loss: -0.0131 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0114 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99963\n",
            "Epoch 25/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0132 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0115 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99963\n",
            "Epoch 26/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0132 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99963\n",
            "Epoch 27/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0133 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99963\n",
            "Epoch 28/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99963\n",
            "Epoch 29/40\n",
            "8577/8577 [==============================] - 120s 14ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0117 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99963\n",
            "Epoch 30/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0135 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99963\n",
            "Epoch 31/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0136 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0117 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99963\n",
            "Epoch 32/40\n",
            "8577/8577 [==============================] - 118s 14ms/step - loss: -0.0137 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99963\n",
            "Epoch 33/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0137 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99963\n",
            "Epoch 34/40\n",
            "8577/8577 [==============================] - 118s 14ms/step - loss: -0.0138 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99963\n",
            "Epoch 35/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0139 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99963\n",
            "Epoch 36/40\n",
            "8577/8577 [==============================] - 117s 14ms/step - loss: -0.0139 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99963\n",
            "Epoch 37/40\n",
            "8577/8577 [==============================] - 118s 14ms/step - loss: -0.0140 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0120 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99963\n",
            "Epoch 38/40\n",
            "8577/8577 [==============================] - 116s 14ms/step - loss: -0.0141 - crf_viterbi_accuracy: 1.0000 - accuracy: 1.2340e-05 - val_loss: -0.0121 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99963\n",
            "Epoch 39/40\n",
            "8577/8577 [==============================] - 115s 13ms/step - loss: -0.0141 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0122 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99963\n",
            "Epoch 40/40\n",
            "8577/8577 [==============================] - 118s 14ms/step - loss: -0.0142 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2340e-05 - val_loss: -0.0122 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkdyfh_PPQDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c92f612d-e215-4653-91fc-1371f1139893"
      },
      "source": [
        "####PLOTS of loss and accuracy\n",
        "# Plot the graph \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "####FIT with the TEST data\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag_all[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "test_pred = model.predict(X_test, verbose=1)   \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(y_test)\n",
        "\n",
        "#####REPORT of the fit\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "print(report)\n",
        "\n",
        "###Rest\n",
        "TP = {}\n",
        "TN = {}\n",
        "FP = {}\n",
        "FN = {}\n",
        "for tag in tag2idx_all.keys():\n",
        "    TP[tag] = 0\n",
        "    TN[tag] = 0    \n",
        "    FP[tag] = 0    \n",
        "    FN[tag] = 0    \n",
        "\n",
        "def accumulate_score_by_tag(gt, pred):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] +=1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "for i, sentence in enumerate(X_test):\n",
        "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "    gt = np.argmax(y_test[0], axis=-1)\n",
        "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
        "        accumulate_score_by_tag(idx2tag_all[gt[idx]],tags_all[pred])\n",
        "\n",
        "for tag in tag2idx_all.keys():\n",
        "    print(f'tag:{tag}')    \n",
        "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
        "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6339/6339 [==============================] - 60s 9ms/step\n",
            "F1-score: 85.3%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-diap       0.86      0.87      0.87       278\n",
            "      B-fndg       0.88      0.85      0.87       925\n",
            "      B-lbpr       0.92      0.88      0.90       130\n",
            "      B-lbtr       0.78      0.58      0.67        12\n",
            "      I-diap       0.86      0.86      0.86       138\n",
            "      I-fndg       0.88      0.81      0.84       844\n",
            "      I-lbpr       0.86      0.79      0.82        62\n",
            "      I-lbtr       0.43      0.38      0.40         8\n",
            "           O       1.00      1.00      1.00   1734489\n",
            "\n",
            "    accuracy                           1.00   1736886\n",
            "   macro avg       0.83      0.78      0.80   1736886\n",
            "weighted avg       1.00      1.00      1.00   1736886\n",
            "\n",
            "tag:B-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:      6339\n",
            "tag:B-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:O\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:   1730547\n",
            "tag:I-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkSW4YUcPP-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "train.to_csv('train.csv')\n",
        "dev.to_csv('dev.csv')\n",
        "test.to_csv('test.csv')\n",
        "train2.to_csv('train2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pahzxl3MPPjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_unstructured=pd.DataFrame({'Test Tag':test_labels,'Predicted Tag':pred_labels})\n",
        "result_unstructured.to_csv('result_unstructured.csv')\n",
        "\n",
        "test_tag_temp01=[[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "test_tag_ind01=[]\n",
        "for i in range(len(test_tag_temp01)):\n",
        "  test_tag_ind01.append(len(test_tag_temp01[i]))\n",
        "\n",
        "predicted_tag_temp01=[]\n",
        "for i in range(len(pred_labels)):\n",
        "  predicted_tag_temp01.extend(pred_labels[i][:test_tag_ind01[i]])\n",
        "\n",
        "result=test.assign(predicted_tag=predicted_tag_temp01)\n",
        "result.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7EvHMZAPfYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}