{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_data_results_transfer_learning_approach_0_40.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNn-CaMriSmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40bc7338-c1c1-470b-f660-e428670e19ce"
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "! pip install seqeval\n",
        "! pip install sklearn_crfsuite\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import nan\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "import keras as k\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#loading train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive//My Drive/entity_train.csv')\n",
        "\n",
        "df1=df[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1[df1['type']=='entity']  #We take only the entities i.e. removing the text and relation types\n",
        "\n",
        "df1=df1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "#loading test data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dftest=pd.read_csv('/content/drive//My Drive/entity_test.csv')\n",
        "\n",
        "dftest1=dftest[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1[dftest1['type']=='entity']  #We take only the entities i.e. removing the text and relation\n",
        "\n",
        "dftest1=dftest1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "###creating sentence id\n",
        "\n",
        "#for train data\n",
        "\n",
        "index_train=df1.index\n",
        "\n",
        "\n",
        "seq_train=[]\n",
        "seq_train.append(df1['sentence_idx'][index_train[0]])\n",
        "for i in range(1,len(index_train)):\n",
        "  seq_train.append(df1['sentence_idx'][index_train[i]]-df1['sentence_idx'][index_train[i-1]])\n",
        "len(seq_train)\n",
        "\n",
        "\n",
        "neg_ind_train=[]\n",
        "for i in range(len(seq_train)):\n",
        "  if seq_train[i]<0:\n",
        "    seq_train[i]=1\n",
        "    neg_ind_train.append(i)\n",
        "\n",
        "df1=df1.assign(ind_train=seq_train)\n",
        "sen_id=df1['ind_train'].cumsum()\n",
        "df1=df1.assign(sentence_idx=sen_id)\n",
        "df1=df1.drop('ind_train',1)\n",
        "df1=df1.dropna()\n",
        "\n",
        "#creating sentence id for test data\n",
        "\n",
        "index_test=dftest1.index\n",
        "\n",
        "\n",
        "seq_test=[]\n",
        "seq_test.append(dftest1['sentence_idx'][index_test[0]])\n",
        "for i in range(1,len(index_test)):\n",
        "  seq_test.append(dftest1['sentence_idx'][index_test[i]]-dftest1['sentence_idx'][index_test[i-1]])\n",
        "len(seq_test)\n",
        "\n",
        "\n",
        "neg_ind_test=[]\n",
        "for i in range(len(seq_test)):\n",
        "  if seq_test[i]<0:\n",
        "    seq_test[i]=1\n",
        "    neg_ind_test.append(i)\n",
        "\n",
        "dftest1=dftest1.assign(ind_test=seq_test)\n",
        "sen_id=dftest1['ind_test'].cumsum()\n",
        "dftest1=dftest1.assign(sentence_idx=sen_id)\n",
        "dftest1=dftest1.drop('ind_test',1)\n",
        "dftest1=dftest1.dropna()\n",
        "\n",
        "#Split test data into 2 half\n",
        "test_sp1, test_sp2 = train_test_split(dftest1, test_size=0.5,random_state=123)\n",
        "\n",
        "dftest_sp1=test_sp1.sort_index(axis = 0)\t# sort by index labels\n",
        "dfdev1, test_sp = train_test_split(test_sp2, test_size=0.5,random_state=123)\t#Split other half test data into dev and test data\n",
        "dfdev1=dfdev1.sort_index(axis=0)\n",
        "test_sp=test_sp.sort_index(axis=0)\n",
        "dftest1=test_sp\n",
        "\n",
        "#Taking only required tags and the rest renamed as others 'O'\n",
        "tag_req=['diap','fndg','lbpr','lbtr']\n",
        "df2=df1[df1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_train=df2.index\n",
        "\n",
        "for i in df1.index:\n",
        "  if i not in req_train:\n",
        "    df1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in df1.tag[i]:\n",
        "      df1.tag[i]='O'\n",
        "\n",
        "dftest2=dftest1[dftest1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test=dftest2.index\n",
        "\n",
        "for i in dftest1.index:\n",
        "  if i not in req_test:\n",
        "    dftest1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest1.tag[i]:\n",
        "      dftest1.tag[i]='O'\n",
        "\n",
        "dfdev2=dfdev1[dfdev1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_dev=dfdev2.index\n",
        "\n",
        "for i in dfdev1.index:\n",
        "  if i not in req_dev:\n",
        "    dfdev1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dfdev1.tag[i]:\n",
        "      dfdev1.tag[i]='O'\n",
        "\n",
        "dftest_sp2=dftest_sp1[dftest_sp1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test_sp=dftest_sp2.index\n",
        "\n",
        "for i in dftest_sp1.index:\n",
        "  if i not in req_test_sp:\n",
        "    dftest_sp1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest_sp1.tag[i]:\n",
        "      dftest_sp1.tag[i]='O'\n",
        "\n",
        "#BIO-tagging For Train Data\n",
        "temp01=pd.DataFrame(df1.word.str.split().tolist(), index=df1['sentence_idx']).stack()\n",
        "d1 = temp01.index\n",
        "t1 = []\n",
        "for i in range(len(d1)):\n",
        "  if d1[i][1] == 0:\n",
        "    t1.append('B-')\n",
        "  else:\n",
        "    t1.append('I-')\n",
        "temp01 = temp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp01.columns = ['word','sentence_idx']\n",
        "temp01=temp01[['sentence_idx','word']]\n",
        "temp01=temp01.assign(bio_tr=t1)\n",
        "\n",
        "temp02=pd.DataFrame(df1.word.str.split().tolist(), index=df1['tag']).stack()\n",
        "temp02 = temp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp02.columns = ['word','tag']\n",
        "\n",
        "temp01[\"tag\"] = temp01[\"bio_tr\"].astype(str) + temp02[\"tag\"]\n",
        "del temp01['bio_tr']\n",
        "temp01['tag']=temp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "df1=temp01\n",
        "\n",
        "#BIO-tagging For Test Data\n",
        "temp_test01=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['sentence_idx']).stack()\n",
        "d1_test = temp_test01.index\n",
        "t1_test = []\n",
        "for i in range(len(d1_test)):\n",
        "  if d1_test[i][1] == 0:\n",
        "    t1_test.append('B-')\n",
        "  else:\n",
        "    t1_test.append('I-')\n",
        "temp_test01 = temp_test01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test01.columns = ['word','sentence_idx']\n",
        "temp_test01=temp_test01[['sentence_idx','word']]\n",
        "temp_test01=temp_test01.assign(bio_te=t1_test)\n",
        "\n",
        "temp_test02=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['tag']).stack()\n",
        "temp_test02 = temp_test02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test02.columns = ['word','tag']\n",
        "\n",
        "temp_test01[\"tag\"] = temp_test01[\"bio_te\"].astype(str) + temp_test02[\"tag\"]\n",
        "del temp_test01['bio_te']\n",
        "temp_test01['tag']=temp_test01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest1=temp_test01\n",
        "\n",
        "#BIO-tagging For dev Data\n",
        "temp_dev01=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['sentence_idx']).stack()\n",
        "d1_dev = temp_dev01.index\n",
        "t1_dev = []\n",
        "for i in range(len(d1_dev)):\n",
        "  if d1_dev[i][1] == 0:\n",
        "    t1_dev.append('B-')\n",
        "  else:\n",
        "    t1_dev.append('I-')\n",
        "temp_dev01 = temp_dev01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_dev01.columns = ['word','sentence_idx']\n",
        "temp_dev01=temp_dev01[['sentence_idx','word']]\n",
        "temp_dev01=temp_dev01.assign(bio_te=t1_dev)\n",
        "\n",
        "temp_dev02=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['tag']).stack()\n",
        "temp_dev02 = temp_dev02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_dev02.columns = ['word','tag']\n",
        "\n",
        "temp_dev01[\"tag\"] = temp_dev01[\"bio_te\"].astype(str) + temp_dev02[\"tag\"]\n",
        "del temp_dev01['bio_te']\n",
        "temp_dev01['tag']=temp_dev01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dfdev1=temp_dev01\n",
        "\n",
        "#BIO-tagging For test split1 Data\n",
        "temp_test_sp01=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['sentence_idx']).stack()\n",
        "d1_test_sp = temp_test_sp01.index\n",
        "t1_test_sp = []\n",
        "for i in range(len(d1_test_sp)):\n",
        "  if d1_test_sp[i][1] == 0:\n",
        "    t1_test_sp.append('B-')\n",
        "  else:\n",
        "    t1_test_sp.append('I-')\n",
        "temp_test_sp01 = temp_test_sp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp01.columns = ['word','sentence_idx']\n",
        "temp_test_sp01=temp_test_sp01[['sentence_idx','word']]\n",
        "temp_test_sp01=temp_test_sp01.assign(bio_te=t1_test_sp)\n",
        "\n",
        "temp_test_sp02=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['tag']).stack()\n",
        "temp_test_sp02 = temp_test_sp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp02.columns = ['word','tag']\n",
        "\n",
        "temp_test_sp01[\"tag\"] = temp_test_sp01[\"bio_te\"].astype(str) + temp_test_sp02[\"tag\"]\n",
        "del temp_test_sp01['bio_te']\n",
        "temp_test_sp01['tag']=temp_test_sp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest_sp1=temp_test_sp01\n",
        "\n",
        "train=df1\n",
        "test=dftest1\n",
        "dev=dfdev1\n",
        "train2=dftest_sp1\n",
        "\n",
        "#Define Sentence Getter\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "#Sentence getter for train\n",
        "getter_train = SentenceGetter(train)\n",
        "sentences_train = getter_train.sentences\n",
        "\n",
        "#Sentence getter for test\n",
        "getter_test = SentenceGetter(test)\n",
        "sentences_test = getter_test.sentences\n",
        "\n",
        "#Sentence getter for dev\n",
        "getter_dev = SentenceGetter(dev)\n",
        "sentences_dev = getter_dev.sentences\n",
        "\n",
        "#Sentence getter for train2\n",
        "getter_train2 = SentenceGetter(train2)\n",
        "sentences_train2 = getter_train2.sentences\n",
        "\n",
        "##formation of words and tags\n",
        "\n",
        "#for train\n",
        "\n",
        "words_train = list(set(train[\"word\"].values))\n",
        "n_words_train = len(words_train)\n",
        "\n",
        "tags_train = []\n",
        "for tag in set(train[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train.append('unk')\n",
        "    else:\n",
        "        tags_train.append(tag)\n",
        "n_tags_train = len(tags_train)\n",
        "\n",
        "#for test\n",
        "words_test = list(set(test[\"word\"].values))\n",
        "n_words_test = len(words_test)\n",
        "\n",
        "tags_test = []\n",
        "for tag in set(test[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_test.append('unk')\n",
        "    else:\n",
        "        tags_test.append(tag)\n",
        "n_tags_test = len(tags_test)\n",
        "\n",
        "#for dev\n",
        "words_dev = list(set(dev[\"word\"].values))\n",
        "n_words_dev = len(words_dev)\n",
        "\n",
        "tags_dev = []\n",
        "for tag in set(dev[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_dev.append('unk')\n",
        "    else:\n",
        "        tags_dev.append(tag)\n",
        "n_tags_dev = len(tags_dev)\n",
        "\n",
        "#for train2\n",
        "words_train2 = list(set(train2[\"word\"].values))\n",
        "n_words_train2 = len(words_train2)\n",
        "\n",
        "tags_train2 = []\n",
        "for tag in set(train2[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train2.append('unk')\n",
        "    else:\n",
        "        tags_train2.append(tag)\n",
        "n_tags_train2 = len(tags_train2)\n",
        "\n",
        "#taking union of train, dev and test\n",
        "\n",
        "words_all = list(set().union(words_train,words_test,words_dev,words_train2))\n",
        "n_words_all = len(words_all)\n",
        "\n",
        "tags_all = list(set().union(tags_train,tags_test,tags_dev,tags_train2))\n",
        "n_tags_all = len(tags_all)\n",
        "\n",
        "##formation of word2id, tag2id and id2tag\n",
        "\n",
        "#for all union of train and test\n",
        "word2idx_all = {w: i for i, w in enumerate(words_all)}\n",
        "tag2idx_all = {t: i for i, t in enumerate(tags_all)}\n",
        "idx2tag_all = {v: k for k, v in iteritems(tag2idx_all)}\n",
        "\n",
        "maxlen_all = max(max([len(s) for s in sentences_train]),max([len(s) for s in sentences_test]),max([len(s) for s in sentences_dev]),max([len(s) for s in sentences_train2]))\n",
        "\n",
        "##vectorisation\n",
        "\n",
        "#for train\n",
        "\n",
        "maxlen_train = max([len(s) for s in sentences_train])\n",
        "\n",
        "X_train = [[word2idx_all[w[0]] for w in s] for s in sentences_train]\n",
        "X_train = pad_sequences(maxlen=maxlen_all, sequences=X_train, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train = [[tag2idx_all[w[1]] for w in s] for s in sentences_train]\n",
        "y_train = pad_sequences(maxlen=maxlen_all, sequences=y_train, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train = [to_categorical(i, num_classes=n_tags_all) for i in y_train]\n",
        "\n",
        "\n",
        "#for test\n",
        "maxlen_test = max([len(s) for s in sentences_test])\n",
        "\n",
        "X_test = [[word2idx_all[w[0]] for w in s] for s in sentences_test]\n",
        "X_test = pad_sequences(maxlen=maxlen_all, sequences=X_test, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_test = [[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "y_test = pad_sequences(maxlen=maxlen_all, sequences=y_test, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_test = [to_categorical(i, num_classes=n_tags_all) for i in y_test]\n",
        "\n",
        "#for dev\n",
        "maxlen_dev = max([len(s) for s in sentences_dev])\n",
        "\n",
        "X_dev = [[word2idx_all[w[0]] for w in s] for s in sentences_dev]\n",
        "X_dev = pad_sequences(maxlen=maxlen_all, sequences=X_dev, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_dev = [[tag2idx_all[w[1]] for w in s] for s in sentences_dev]\n",
        "y_dev = pad_sequences(maxlen=maxlen_all, sequences=y_dev, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_dev = [to_categorical(i, num_classes=n_tags_all) for i in y_dev]\n",
        "\n",
        "#for train2\n",
        "maxlen_train2 = max([len(s) for s in sentences_train2])\n",
        "\n",
        "X_train2 = [[word2idx_all[w[0]] for w in s] for s in sentences_train2]\n",
        "X_train2 = pad_sequences(maxlen=maxlen_all, sequences=X_train2, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train2 = [[tag2idx_all[w[1]] for w in s] for s in sentences_train2]\n",
        "y_train2 = pad_sequences(maxlen=maxlen_all, sequences=y_train2, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train2 = [to_categorical(i, num_classes=n_tags_all) for i in y_train2]\n",
        "\n",
        "##MODEL\n",
        "\n",
        "input = Input(shape=(max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]),))\n",
        "word_embedding_size = 180\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=n_words_all, output_dim=word_embedding_size, input_length=max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]))(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(n_tags_all, activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(n_tags_all)\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "##FIT MODEL\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Saving the best model only\n",
        "filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-szyjeok0\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-szyjeok0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=fe03fd14fc0ed4bf954da140c6d6773cb284f1ede0ee3e98f8d9ae8f41c63135\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-of_ecj26/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=bccd8bf390a6f39e4a505c4c46de0c37e6a09b244de66a25fdcebfc96af8e3e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18,19,20,24,25,32,33,47,48,49,50,51,52,53,54,60,61,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:136: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:150: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 274)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 274, 180)          3860640   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 274, 360)          519840    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 274, 360)          1038240   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 274, 9)            3249      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 274, 9)            189       \n",
            "=================================================================\n",
            "Total params: 5,422,158\n",
            "Trainable params: 5,422,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHOVx-GzjUQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7cca436-3e00-4b68-d203-74ae9a9c24ae"
      },
      "source": [
        "# Fit the best model with train data\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=40, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 44782 samples, validate on 4976 samples\n",
            "Epoch 1/40\n",
            "44782/44782 [==============================] - 340s 8ms/step - loss: 0.0653 - crf_viterbi_accuracy: 0.9916 - accuracy: 1.0652e-04 - val_loss: 0.0205 - val_crf_viterbi_accuracy: 0.9968 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99686, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: 0.0181 - crf_viterbi_accuracy: 0.9970 - accuracy: 1.0652e-04 - val_loss: 0.0163 - val_crf_viterbi_accuracy: 0.9968 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.99686\n",
            "Epoch 3/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: 0.0140 - crf_viterbi_accuracy: 0.9969 - accuracy: 1.0652e-04 - val_loss: 0.0117 - val_crf_viterbi_accuracy: 0.9968 - val_accuracy: 0.9969\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.99686 to 0.99686, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 4/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: 0.0105 - crf_viterbi_accuracy: 0.9972 - accuracy: 1.0652e-04 - val_loss: 0.0093 - val_crf_viterbi_accuracy: 0.9974 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99686 to 0.99746, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: 0.0085 - crf_viterbi_accuracy: 0.9977 - accuracy: 1.0652e-04 - val_loss: 0.0079 - val_crf_viterbi_accuracy: 0.9979 - val_accuracy: 0.9979\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99746 to 0.99793, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: 0.0071 - crf_viterbi_accuracy: 0.9980 - accuracy: 1.0652e-04 - val_loss: 0.0070 - val_crf_viterbi_accuracy: 0.9981 - val_accuracy: 0.9981\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99793 to 0.99811, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: 0.0062 - crf_viterbi_accuracy: 0.9982 - accuracy: 1.0652e-04 - val_loss: 0.0062 - val_crf_viterbi_accuracy: 0.9982 - val_accuracy: 0.9982\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99811 to 0.99821, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "44782/44782 [==============================] - 336s 7ms/step - loss: 0.0054 - crf_viterbi_accuracy: 0.9983 - accuracy: 1.0652e-04 - val_loss: 0.0055 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99821 to 0.99829, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 9/40\n",
            "44782/44782 [==============================] - 336s 7ms/step - loss: 0.0045 - crf_viterbi_accuracy: 0.9985 - accuracy: 1.0652e-04 - val_loss: 0.0049 - val_crf_viterbi_accuracy: 0.9984 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99829 to 0.99836, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: 0.0037 - crf_viterbi_accuracy: 0.9986 - accuracy: 1.0652e-04 - val_loss: 0.0042 - val_crf_viterbi_accuracy: 0.9985 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99836 to 0.99854, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "44782/44782 [==============================] - 336s 8ms/step - loss: 0.0030 - crf_viterbi_accuracy: 0.9987 - accuracy: 1.0652e-04 - val_loss: 0.0037 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99854 to 0.99857, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: 0.0024 - crf_viterbi_accuracy: 0.9988 - accuracy: 1.0652e-04 - val_loss: 0.0033 - val_crf_viterbi_accuracy: 0.9987 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.99857 to 0.99872, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 13/40\n",
            "44782/44782 [==============================] - 338s 8ms/step - loss: 0.0018 - crf_viterbi_accuracy: 0.9989 - accuracy: 1.0652e-04 - val_loss: 0.0029 - val_crf_viterbi_accuracy: 0.9988 - val_accuracy: 0.9988\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99872 to 0.99883, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/40\n",
            "44782/44782 [==============================] - 339s 8ms/step - loss: 0.0014 - crf_viterbi_accuracy: 0.9990 - accuracy: 1.0652e-04 - val_loss: 0.0022 - val_crf_viterbi_accuracy: 0.9989 - val_accuracy: 0.9989\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99883 to 0.99887, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 15/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: 8.1415e-04 - crf_viterbi_accuracy: 0.9991 - accuracy: 1.0652e-04 - val_loss: 0.0019 - val_crf_viterbi_accuracy: 0.9989 - val_accuracy: 0.9989\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.99887 to 0.99894, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 16/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: 2.2107e-04 - crf_viterbi_accuracy: 0.9992 - accuracy: 1.0652e-04 - val_loss: 0.0014 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.99894 to 0.99899, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 17/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: -3.1331e-04 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.0652e-04 - val_loss: 0.0010 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.99899 to 0.99902, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 18/40\n",
            "44782/44782 [==============================] - 337s 8ms/step - loss: -8.0788e-04 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.0652e-04 - val_loss: 6.1863e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.99902 to 0.99909, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 19/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0013 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0652e-04 - val_loss: 3.1022e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.99909 to 0.99915, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 20/40\n",
            "44782/44782 [==============================] - 336s 7ms/step - loss: -0.0017 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0652e-04 - val_loss: -1.6012e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99915\n",
            "Epoch 21/40\n",
            "44782/44782 [==============================] - 336s 8ms/step - loss: -0.0021 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0652e-04 - val_loss: -3.2712e-04 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.99915 to 0.99916, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 22/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0025 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0652e-04 - val_loss: -8.7086e-04 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99916\n",
            "Epoch 23/40\n",
            "44782/44782 [==============================] - 336s 8ms/step - loss: -0.0030 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0652e-04 - val_loss: -0.0012 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99916\n",
            "Epoch 24/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0034 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0652e-04 - val_loss: -0.0015 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99916\n",
            "Epoch 25/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0019 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.99916 to 0.99918, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 26/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: -0.0041 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0022 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.99918 to 0.99919, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 27/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0045 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0025 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.99919 to 0.99919, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 28/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0049 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0029 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99919\n",
            "Epoch 29/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0053 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0033 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99919\n",
            "Epoch 30/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0056 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0652e-04 - val_loss: -0.0035 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.99919 to 0.99921, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 31/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0060 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0038 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99921\n",
            "Epoch 32/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: -0.0064 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0042 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99921\n",
            "Epoch 33/40\n",
            "44782/44782 [==============================] - 336s 7ms/step - loss: -0.0067 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0046 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99921\n",
            "Epoch 34/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: -0.0070 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0048 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99921\n",
            "Epoch 35/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0074 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0052 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99921\n",
            "Epoch 36/40\n",
            "44782/44782 [==============================] - 334s 7ms/step - loss: -0.0078 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0055 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99921\n",
            "Epoch 37/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0081 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0652e-04 - val_loss: -0.0057 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99921\n",
            "Epoch 38/40\n",
            "44782/44782 [==============================] - 335s 7ms/step - loss: -0.0085 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.0652e-04 - val_loss: -0.0060 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.99921 to 0.99921, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 39/40\n",
            "44782/44782 [==============================] - 336s 8ms/step - loss: -0.0088 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.0652e-04 - val_loss: -0.0064 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99921\n",
            "Epoch 40/40\n",
            "44782/44782 [==============================] - 336s 8ms/step - loss: -0.0092 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.0652e-04 - val_loss: -0.0068 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9992\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55pJUc6djuj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78566910-069a-4bb2-e10b-63110858e14a"
      },
      "source": [
        "# Fit the best model with train2 data\n",
        "history = model.fit(X_train2, np.array(y_train2), batch_size=256, epochs=40, validation_data=(X_dev, np.array(y_dev)), verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 27810 samples, validate on 20655 samples\n",
            "Epoch 1/40\n",
            "27810/27810 [==============================] - 234s 8ms/step - loss: -0.0078 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.2218e-04 - val_loss: -0.0090 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00001: val_accuracy improved from 0.99921 to 0.99965, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "27810/27810 [==============================] - 233s 8ms/step - loss: -0.0087 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2218e-04 - val_loss: -0.0094 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.99965 to 0.99967, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 3/40\n",
            "27810/27810 [==============================] - 231s 8ms/step - loss: -0.0092 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2218e-04 - val_loss: -0.0096 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.99967\n",
            "Epoch 4/40\n",
            "27810/27810 [==============================] - 231s 8ms/step - loss: -0.0096 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2218e-04 - val_loss: -0.0098 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99967 to 0.99967, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0099 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2218e-04 - val_loss: -0.0099 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.99967\n",
            "Epoch 6/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0102 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0101 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99967 to 0.99969, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0105 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0104 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.99969\n",
            "Epoch 8/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0108 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0105 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99969\n",
            "Epoch 9/40\n",
            "27810/27810 [==============================] - 233s 8ms/step - loss: -0.0110 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0107 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.99969\n",
            "Epoch 10/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0113 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0108 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99969\n",
            "Epoch 11/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0115 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0111 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.99969\n",
            "Epoch 12/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0118 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99969\n",
            "Epoch 13/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0120 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0114 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99969\n",
            "Epoch 14/40\n",
            "27810/27810 [==============================] - 232s 8ms/step - loss: -0.0122 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0116 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99969\n",
            "Epoch 15/40\n",
            "27810/27810 [==============================] - 231s 8ms/step - loss: -0.0124 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0118 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99969\n",
            "Epoch 16/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0119 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99969\n",
            "Epoch 17/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0129 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0121 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99969\n",
            "Epoch 18/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0131 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0123 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99969\n",
            "Epoch 19/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0133 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0124 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99969\n",
            "Epoch 20/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0135 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0127 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99969\n",
            "Epoch 21/40\n",
            "27810/27810 [==============================] - 228s 8ms/step - loss: -0.0137 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0128 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99969\n",
            "Epoch 22/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0139 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0131 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99969\n",
            "Epoch 23/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0141 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0132 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99969\n",
            "Epoch 24/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0144 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0134 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99969\n",
            "Epoch 25/40\n",
            "27810/27810 [==============================] - 231s 8ms/step - loss: -0.0146 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0136 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99969\n",
            "Epoch 26/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0148 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0137 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99969\n",
            "Epoch 27/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0150 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0139 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99969\n",
            "Epoch 28/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0152 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0141 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99969\n",
            "Epoch 29/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0154 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0144 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99969\n",
            "Epoch 30/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0156 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0145 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99969\n",
            "Epoch 31/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0158 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0146 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99969\n",
            "Epoch 32/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0160 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0148 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99969\n",
            "Epoch 33/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0162 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0151 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99969\n",
            "Epoch 34/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0164 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0153 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99969\n",
            "Epoch 35/40\n",
            "27810/27810 [==============================] - 231s 8ms/step - loss: -0.0166 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0154 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99969\n",
            "Epoch 36/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0168 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0156 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99969\n",
            "Epoch 37/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0170 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0158 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99969\n",
            "Epoch 38/40\n",
            "27810/27810 [==============================] - 232s 8ms/step - loss: -0.0172 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0160 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99969\n",
            "Epoch 39/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0174 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0162 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99969\n",
            "Epoch 40/40\n",
            "27810/27810 [==============================] - 230s 8ms/step - loss: -0.0176 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0164 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcDEoTabWB9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c822705-e4e2-4c53-aee7-2d006d0c94a3"
      },
      "source": [
        "####PLOTS of loss and accuracy\n",
        "# Plot the graph \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "####FIT with the TEST data\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag_all[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "test_pred = model.predict(X_test, verbose=1)   \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(y_test)\n",
        "\n",
        "#####REPORT of the fit\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "print(report)\n",
        "\n",
        "###Rest\n",
        "TP = {}\n",
        "TN = {}\n",
        "FP = {}\n",
        "FN = {}\n",
        "for tag in tag2idx_all.keys():\n",
        "    TP[tag] = 0\n",
        "    TN[tag] = 0    \n",
        "    FP[tag] = 0    \n",
        "    FN[tag] = 0    \n",
        "\n",
        "def accumulate_score_by_tag(gt, pred):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] +=1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "for i, sentence in enumerate(X_test):\n",
        "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "    gt = np.argmax(y_test[0], axis=-1)\n",
        "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
        "        accumulate_score_by_tag(idx2tag_all[gt[idx]],tags_all[pred])\n",
        "\n",
        "for tag in tag2idx_all.keys():\n",
        "    print(f'tag:{tag}')    \n",
        "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
        "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20625/20625 [==============================] - 127s 6ms/step\n",
            "F1-score: 87.0%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-diap       0.90      0.90      0.90       878\n",
            "      B-fndg       0.89      0.87      0.88      2971\n",
            "      B-lbpr       0.90      0.92      0.91       443\n",
            "      B-lbtr       0.76      0.59      0.67        59\n",
            "      I-diap       0.87      0.86      0.86       470\n",
            "      I-fndg       0.84      0.82      0.83      2520\n",
            "      I-lbpr       0.77      0.86      0.81       208\n",
            "      I-lbtr       0.81      0.54      0.65        72\n",
            "           O       1.00      1.00      1.00   5643629\n",
            "\n",
            "    accuracy                           1.00   5651250\n",
            "   macro avg       0.86      0.82      0.83   5651250\n",
            "weighted avg       1.00      1.00      1.00   5651250\n",
            "\n",
            "tag:I-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n",
            "tag:B-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:O\n",
            "\t TN:         0\tFP:     41250\n",
            "\t FN:         0\tTP:   5568750\n",
            "tag:I-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n",
            "tag:I-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYUskFoWB2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "train.to_csv('train.csv')\n",
        "dev.to_csv('dev.csv')\n",
        "test.to_csv('test.csv')\n",
        "train2.to_csv('train2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-mgvceqWHOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_unstructured=pd.DataFrame({'Test Tag':test_labels,'Predicted Tag':pred_labels})\n",
        "result_unstructured.to_csv('result_unstructured.csv')\n",
        "\n",
        "test_tag_temp01=[[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "test_tag_ind01=[]\n",
        "for i in range(len(test_tag_temp01)):\n",
        "  test_tag_ind01.append(len(test_tag_temp01[i]))\n",
        "\n",
        "predicted_tag_temp01=[]\n",
        "for i in range(len(pred_labels)):\n",
        "  predicted_tag_temp01.extend(pred_labels[i][:test_tag_ind01[i]])\n",
        "\n",
        "result=test.assign(predicted_tag=predicted_tag_temp01)\n",
        "result.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxgs3r6OWHIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}