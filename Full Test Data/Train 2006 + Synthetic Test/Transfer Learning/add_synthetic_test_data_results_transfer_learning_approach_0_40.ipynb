{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "add_synthetic_test_data_results_transfer_learning_approach_0_40.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjAXhMsiBw8t",
        "colab_type": "code",
        "outputId": "faecb2b7-1710-4c9a-cc09-9bfa15f85716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "! pip install seqeval\n",
        "! pip install sklearn_crfsuite\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from math import nan\n",
        "from future.utils import iteritems\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "import keras as k\n",
        "from keras_contrib.layers import CRF\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#loading train data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df=pd.read_csv('/content/drive//My Drive/entity_train.csv')\n",
        "synth_df=pd.read_csv('/content/drive//My Drive/entity_synth_test.csv')\n",
        "df=pd.concat([df,synth_df]).reset_index(drop=True)\n",
        "\n",
        "df1=df[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1[df1['type']=='entity']  #We take only the entities i.e. removing the text and relation types\n",
        "\n",
        "df1=df1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "df1=df1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "#loading test data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dftest=pd.read_csv('/content/drive//My Drive/entity_test.csv')\n",
        "\n",
        "dftest1=dftest[['type','Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1[dftest1['type']=='entity']  #We take only the entities i.e. removing the text and relation\n",
        "\n",
        "dftest1=dftest1[['Sentence ID','Text','Semantic Type']]\n",
        "\n",
        "dftest1=dftest1.rename(columns={'Sentence ID':'sentence_idx','Text':'word','Semantic Type':'tag'})\n",
        "\n",
        "###creating sentence id\n",
        "\n",
        "#for train data\n",
        "\n",
        "index_train=df1.index\n",
        "\n",
        "\n",
        "seq_train=[]\n",
        "seq_train.append(df1['sentence_idx'][index_train[0]])\n",
        "for i in range(1,len(index_train)):\n",
        "  seq_train.append(df1['sentence_idx'][index_train[i]]-df1['sentence_idx'][index_train[i-1]])\n",
        "len(seq_train)\n",
        "\n",
        "\n",
        "neg_ind_train=[]\n",
        "for i in range(len(seq_train)):\n",
        "  if seq_train[i]<0:\n",
        "    seq_train[i]=1\n",
        "    neg_ind_train.append(i)\n",
        "\n",
        "df1=df1.assign(ind_train=seq_train)\n",
        "sen_id=df1['ind_train'].cumsum()\n",
        "df1=df1.assign(sentence_idx=sen_id)\n",
        "df1=df1.drop('ind_train',1)\n",
        "df1=df1.dropna()\n",
        "\n",
        "#creating sentence id for test data\n",
        "\n",
        "index_test=dftest1.index\n",
        "\n",
        "\n",
        "seq_test=[]\n",
        "seq_test.append(dftest1['sentence_idx'][index_test[0]])\n",
        "for i in range(1,len(index_test)):\n",
        "  seq_test.append(dftest1['sentence_idx'][index_test[i]]-dftest1['sentence_idx'][index_test[i-1]])\n",
        "len(seq_test)\n",
        "\n",
        "\n",
        "neg_ind_test=[]\n",
        "for i in range(len(seq_test)):\n",
        "  if seq_test[i]<0:\n",
        "    seq_test[i]=1\n",
        "    neg_ind_test.append(i)\n",
        "\n",
        "dftest1=dftest1.assign(ind_test=seq_test)\n",
        "sen_id=dftest1['ind_test'].cumsum()\n",
        "dftest1=dftest1.assign(sentence_idx=sen_id)\n",
        "dftest1=dftest1.drop('ind_test',1)\n",
        "dftest1=dftest1.dropna()\n",
        "\n",
        "#Split test data into 2 half\n",
        "test_sp1, test_sp2 = train_test_split(dftest1, test_size=0.5,random_state=123)\n",
        "\n",
        "dftest_sp1=test_sp1.sort_index(axis = 0)\t# sort by index labels\n",
        "dfdev1, test_sp = train_test_split(test_sp2, test_size=0.5,random_state=123)\t#Split other half test data into dev and test data\n",
        "dfdev1=dfdev1.sort_index(axis=0)\n",
        "test_sp=test_sp.sort_index(axis=0)\n",
        "dftest1=test_sp\n",
        "\n",
        "#Taking only required tags and the rest renamed as others 'O'\n",
        "tag_req=['diap','fndg','lbpr','lbtr']\n",
        "df2=df1[df1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_train=df2.index\n",
        "\n",
        "for i in df1.index:\n",
        "  if i not in req_train:\n",
        "    df1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in df1.tag[i]:\n",
        "      df1.tag[i]='O'\n",
        "\n",
        "dftest2=dftest1[dftest1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test=dftest2.index\n",
        "\n",
        "for i in dftest1.index:\n",
        "  if i not in req_test:\n",
        "    dftest1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest1.tag[i]:\n",
        "      dftest1.tag[i]='O'\n",
        "\n",
        "dfdev2=dfdev1[dfdev1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_dev=dfdev2.index\n",
        "\n",
        "for i in dfdev1.index:\n",
        "  if i not in req_dev:\n",
        "    dfdev1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dfdev1.tag[i]:\n",
        "      dfdev1.tag[i]='O'\n",
        "\n",
        "dftest_sp2=dftest_sp1[dftest_sp1.tag.str.contains('|'.join(tag_req))]\n",
        "\n",
        "req_test_sp=dftest_sp2.index\n",
        "\n",
        "for i in dftest_sp1.index:\n",
        "  if i not in req_test_sp:\n",
        "    dftest_sp1.tag[i]='O'\n",
        "  else:\n",
        "    if ',' in dftest_sp1.tag[i]:\n",
        "      dftest_sp1.tag[i]='O'\n",
        "\n",
        "#BIO-tagging For Train Data\n",
        "temp01=pd.DataFrame(df1.word.str.split().tolist(), index=df1['sentence_idx']).stack()\n",
        "d1 = temp01.index\n",
        "t1 = []\n",
        "for i in range(len(d1)):\n",
        "  if d1[i][1] == 0:\n",
        "    t1.append('B-')\n",
        "  else:\n",
        "    t1.append('I-')\n",
        "temp01 = temp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp01.columns = ['word','sentence_idx']\n",
        "temp01=temp01[['sentence_idx','word']]\n",
        "temp01=temp01.assign(bio_tr=t1)\n",
        "\n",
        "temp02=pd.DataFrame(df1.word.str.split().tolist(), index=df1['tag']).stack()\n",
        "temp02 = temp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp02.columns = ['word','tag']\n",
        "\n",
        "temp01[\"tag\"] = temp01[\"bio_tr\"].astype(str) + temp02[\"tag\"]\n",
        "del temp01['bio_tr']\n",
        "temp01['tag']=temp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "df1=temp01\n",
        "\n",
        "#BIO-tagging For Test Data\n",
        "temp_test01=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['sentence_idx']).stack()\n",
        "d1_test = temp_test01.index\n",
        "t1_test = []\n",
        "for i in range(len(d1_test)):\n",
        "  if d1_test[i][1] == 0:\n",
        "    t1_test.append('B-')\n",
        "  else:\n",
        "    t1_test.append('I-')\n",
        "temp_test01 = temp_test01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test01.columns = ['word','sentence_idx']\n",
        "temp_test01=temp_test01[['sentence_idx','word']]\n",
        "temp_test01=temp_test01.assign(bio_te=t1_test)\n",
        "\n",
        "temp_test02=pd.DataFrame(dftest1.word.str.split().tolist(), index=dftest1['tag']).stack()\n",
        "temp_test02 = temp_test02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test02.columns = ['word','tag']\n",
        "\n",
        "temp_test01[\"tag\"] = temp_test01[\"bio_te\"].astype(str) + temp_test02[\"tag\"]\n",
        "del temp_test01['bio_te']\n",
        "temp_test01['tag']=temp_test01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest1=temp_test01\n",
        "\n",
        "#BIO-tagging For dev Data\n",
        "temp_dev01=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['sentence_idx']).stack()\n",
        "d1_dev = temp_dev01.index\n",
        "t1_dev = []\n",
        "for i in range(len(d1_dev)):\n",
        "  if d1_dev[i][1] == 0:\n",
        "    t1_dev.append('B-')\n",
        "  else:\n",
        "    t1_dev.append('I-')\n",
        "temp_dev01 = temp_dev01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_dev01.columns = ['word','sentence_idx']\n",
        "temp_dev01=temp_dev01[['sentence_idx','word']]\n",
        "temp_dev01=temp_dev01.assign(bio_te=t1_dev)\n",
        "\n",
        "temp_dev02=pd.DataFrame(dfdev1.word.str.split().tolist(), index=dfdev1['tag']).stack()\n",
        "temp_dev02 = temp_dev02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_dev02.columns = ['word','tag']\n",
        "\n",
        "temp_dev01[\"tag\"] = temp_dev01[\"bio_te\"].astype(str) + temp_dev02[\"tag\"]\n",
        "del temp_dev01['bio_te']\n",
        "temp_dev01['tag']=temp_dev01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dfdev1=temp_dev01\n",
        "\n",
        "#BIO-tagging For test split1 Data\n",
        "temp_test_sp01=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['sentence_idx']).stack()\n",
        "d1_test_sp = temp_test_sp01.index\n",
        "t1_test_sp = []\n",
        "for i in range(len(d1_test_sp)):\n",
        "  if d1_test_sp[i][1] == 0:\n",
        "    t1_test_sp.append('B-')\n",
        "  else:\n",
        "    t1_test_sp.append('I-')\n",
        "temp_test_sp01 = temp_test_sp01.reset_index()[[0, 'sentence_idx']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp01.columns = ['word','sentence_idx']\n",
        "temp_test_sp01=temp_test_sp01[['sentence_idx','word']]\n",
        "temp_test_sp01=temp_test_sp01.assign(bio_te=t1_test_sp)\n",
        "\n",
        "temp_test_sp02=pd.DataFrame(dftest_sp1.word.str.split().tolist(), index=dftest_sp1['tag']).stack()\n",
        "temp_test_sp02 = temp_test_sp02.reset_index()[[0, 'tag']] # 'word' variable is currently labeled 0\n",
        "temp_test_sp02.columns = ['word','tag']\n",
        "\n",
        "temp_test_sp01[\"tag\"] = temp_test_sp01[\"bio_te\"].astype(str) + temp_test_sp02[\"tag\"]\n",
        "del temp_test_sp01['bio_te']\n",
        "temp_test_sp01['tag']=temp_test_sp01['tag'].replace(['B-O','I-O'],'O')\n",
        "\n",
        "dftest_sp1=temp_test_sp01\n",
        "\n",
        "train=df1\n",
        "test=dftest1\n",
        "dev=dfdev1\n",
        "train2=dftest_sp1\n",
        "\n",
        "#Define Sentence Getter\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "#Sentence getter for train\n",
        "getter_train = SentenceGetter(train)\n",
        "sentences_train = getter_train.sentences\n",
        "\n",
        "#Sentence getter for test\n",
        "getter_test = SentenceGetter(test)\n",
        "sentences_test = getter_test.sentences\n",
        "\n",
        "#Sentence getter for dev\n",
        "getter_dev = SentenceGetter(dev)\n",
        "sentences_dev = getter_dev.sentences\n",
        "\n",
        "#Sentence getter for train2\n",
        "getter_train2 = SentenceGetter(train2)\n",
        "sentences_train2 = getter_train2.sentences\n",
        "\n",
        "##formation of words and tags\n",
        "\n",
        "#for train\n",
        "\n",
        "words_train = list(set(train[\"word\"].values))\n",
        "n_words_train = len(words_train)\n",
        "\n",
        "tags_train = []\n",
        "for tag in set(train[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train.append('unk')\n",
        "    else:\n",
        "        tags_train.append(tag)\n",
        "n_tags_train = len(tags_train)\n",
        "\n",
        "#for test\n",
        "words_test = list(set(test[\"word\"].values))\n",
        "n_words_test = len(words_test)\n",
        "\n",
        "tags_test = []\n",
        "for tag in set(test[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_test.append('unk')\n",
        "    else:\n",
        "        tags_test.append(tag)\n",
        "n_tags_test = len(tags_test)\n",
        "\n",
        "#for dev\n",
        "words_dev = list(set(dev[\"word\"].values))\n",
        "n_words_dev = len(words_dev)\n",
        "\n",
        "tags_dev = []\n",
        "for tag in set(dev[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_dev.append('unk')\n",
        "    else:\n",
        "        tags_dev.append(tag)\n",
        "n_tags_dev = len(tags_dev)\n",
        "\n",
        "#for train2\n",
        "words_train2 = list(set(train2[\"word\"].values))\n",
        "n_words_train2 = len(words_train2)\n",
        "\n",
        "tags_train2 = []\n",
        "for tag in set(train2[\"tag\"].values):\n",
        "    if tag is nan or isinstance(tag, float):\n",
        "        tags_train2.append('unk')\n",
        "    else:\n",
        "        tags_train2.append(tag)\n",
        "n_tags_train2 = len(tags_train2)\n",
        "\n",
        "#taking union of train, dev and test\n",
        "\n",
        "words_all = list(set().union(words_train,words_test,words_dev,words_train2))\n",
        "n_words_all = len(words_all)\n",
        "\n",
        "tags_all = list(set().union(tags_train,tags_test,tags_dev,tags_train2))\n",
        "n_tags_all = len(tags_all)\n",
        "\n",
        "##formation of word2id, tag2id and id2tag\n",
        "\n",
        "#for all union of train and test\n",
        "word2idx_all = {w: i for i, w in enumerate(words_all)}\n",
        "tag2idx_all = {t: i for i, t in enumerate(tags_all)}\n",
        "idx2tag_all = {v: k for k, v in iteritems(tag2idx_all)}\n",
        "\n",
        "maxlen_all = max(max([len(s) for s in sentences_train]),max([len(s) for s in sentences_test]),max([len(s) for s in sentences_dev]),max([len(s) for s in sentences_train2]))\n",
        "\n",
        "##vectorisation\n",
        "\n",
        "#for train\n",
        "\n",
        "maxlen_train = max([len(s) for s in sentences_train])\n",
        "\n",
        "X_train = [[word2idx_all[w[0]] for w in s] for s in sentences_train]\n",
        "X_train = pad_sequences(maxlen=maxlen_all, sequences=X_train, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train = [[tag2idx_all[w[1]] for w in s] for s in sentences_train]\n",
        "y_train = pad_sequences(maxlen=maxlen_all, sequences=y_train, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train = [to_categorical(i, num_classes=n_tags_all) for i in y_train]\n",
        "\n",
        "\n",
        "#for test\n",
        "maxlen_test = max([len(s) for s in sentences_test])\n",
        "\n",
        "X_test = [[word2idx_all[w[0]] for w in s] for s in sentences_test]\n",
        "X_test = pad_sequences(maxlen=maxlen_all, sequences=X_test, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_test = [[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "y_test = pad_sequences(maxlen=maxlen_all, sequences=y_test, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_test = [to_categorical(i, num_classes=n_tags_all) for i in y_test]\n",
        "\n",
        "#for dev\n",
        "maxlen_dev = max([len(s) for s in sentences_dev])\n",
        "\n",
        "X_dev = [[word2idx_all[w[0]] for w in s] for s in sentences_dev]\n",
        "X_dev = pad_sequences(maxlen=maxlen_all, sequences=X_dev, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_dev = [[tag2idx_all[w[1]] for w in s] for s in sentences_dev]\n",
        "y_dev = pad_sequences(maxlen=maxlen_all, sequences=y_dev, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_dev = [to_categorical(i, num_classes=n_tags_all) for i in y_dev]\n",
        "\n",
        "#for train2\n",
        "maxlen_train2 = max([len(s) for s in sentences_train2])\n",
        "\n",
        "X_train2 = [[word2idx_all[w[0]] for w in s] for s in sentences_train2]\n",
        "X_train2 = pad_sequences(maxlen=maxlen_all, sequences=X_train2, padding=\"post\",value=n_words_all - 1)\n",
        "\n",
        "y_train2 = [[tag2idx_all[w[1]] for w in s] for s in sentences_train2]\n",
        "y_train2 = pad_sequences(maxlen=maxlen_all, sequences=y_train2, padding=\"post\", value=tag2idx_all[\"O\"])\n",
        "y_train2 = [to_categorical(i, num_classes=n_tags_all) for i in y_train2]\n",
        "\n",
        "##MODEL\n",
        "\n",
        "input = Input(shape=(max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]),))\n",
        "word_embedding_size = 180\n",
        "\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=n_words_all, output_dim=word_embedding_size, input_length=max(X_train.shape[1],X_dev.shape[1],X_test.shape[1],X_train2.shape[1]))(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=word_embedding_size, \n",
        "                           return_sequences=True, \n",
        "                           dropout=0.5, \n",
        "                           recurrent_dropout=0.5, \n",
        "                           kernel_initializer=k.initializers.he_normal()))(model)\n",
        "model = LSTM(units=word_embedding_size * 2, \n",
        "             return_sequences=True, \n",
        "             dropout=0.5, \n",
        "             recurrent_dropout=0.5, \n",
        "             kernel_initializer=k.initializers.he_normal())(model)\n",
        "\n",
        "# TimeDistributed Layer\n",
        "model = TimeDistributed(Dense(n_tags_all, activation=\"relu\"))(model)  \n",
        "\n",
        "# CRF Layer\n",
        "crf = CRF(n_tags_all)\n",
        "\n",
        "out = crf(model)  # output\n",
        "model = Model(input, out)\n",
        "\n",
        "##FIT MODEL\n",
        "\n",
        "#Optimiser \n",
        "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Saving the best model only\n",
        "filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-cg9vemr_\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-cg9vemr_\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=b5da2299ecdf9da2baada0cdfa9472a0dbff739b98a968a9a942e151e9ffa1ae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cys46r50/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=e25c21a3ce68736248e97bd65b6d1ba92c2c187af87810609da28ec676b13123\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18,19,20,24,25,32,33,47,48,49,50,51,52,53,54,60,61,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:116: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:149: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 274)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 274, 180)          4031280   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 274, 360)          519840    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 274, 360)          1038240   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 274, 9)            3249      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 274, 9)            189       \n",
            "=================================================================\n",
            "Total params: 5,592,798\n",
            "Trainable params: 5,592,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3icYi_HCNcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c97b9574-6c64-4922-917e-69e343189333"
      },
      "source": [
        "# Fit the best model with train data\n",
        "history = model.fit(X_train, np.array(y_train), batch_size=256, epochs=40, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 46502 samples, validate on 5167 samples\n",
            "Epoch 1/40\n",
            "46502/46502 [==============================] - 349s 8ms/step - loss: 0.0735 - crf_viterbi_accuracy: 0.9803 - accuracy: 1.0580e-04 - val_loss: 0.0115 - val_crf_viterbi_accuracy: 0.9975 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99743, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "46502/46502 [==============================] - 343s 7ms/step - loss: 0.0128 - crf_viterbi_accuracy: 0.9970 - accuracy: 1.0580e-04 - val_loss: 0.0095 - val_crf_viterbi_accuracy: 0.9975 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.99743\n",
            "Epoch 3/40\n",
            "46502/46502 [==============================] - 341s 7ms/step - loss: 0.0098 - crf_viterbi_accuracy: 0.9970 - accuracy: 1.0580e-04 - val_loss: 0.0061 - val_crf_viterbi_accuracy: 0.9979 - val_accuracy: 0.9979\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.99743 to 0.99786, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 4/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: 0.0061 - crf_viterbi_accuracy: 0.9977 - accuracy: 1.0580e-04 - val_loss: 0.0043 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99786 to 0.99826, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: 0.0045 - crf_viterbi_accuracy: 0.9980 - accuracy: 1.0580e-04 - val_loss: 0.0033 - val_crf_viterbi_accuracy: 0.9983 - val_accuracy: 0.9983\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.99826 to 0.99830, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 6/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: 0.0035 - crf_viterbi_accuracy: 0.9981 - accuracy: 1.0580e-04 - val_loss: 0.0026 - val_crf_viterbi_accuracy: 0.9985 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99830 to 0.99842, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 7/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: 0.0026 - crf_viterbi_accuracy: 0.9982 - accuracy: 1.0580e-04 - val_loss: 0.0021 - val_crf_viterbi_accuracy: 0.9985 - val_accuracy: 0.9984\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99842 to 0.99843, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: 0.0018 - crf_viterbi_accuracy: 0.9984 - accuracy: 1.0580e-04 - val_loss: 0.0015 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9985\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99843 to 0.99855, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 9/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: 9.2346e-04 - crf_viterbi_accuracy: 0.9985 - accuracy: 1.0580e-04 - val_loss: 9.0335e-04 - val_crf_viterbi_accuracy: 0.9986 - val_accuracy: 0.9986\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99855 to 0.99856, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: 2.7697e-05 - crf_viterbi_accuracy: 0.9986 - accuracy: 1.0580e-04 - val_loss: 3.0549e-04 - val_crf_viterbi_accuracy: 0.9987 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99856 to 0.99866, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -8.1166e-04 - crf_viterbi_accuracy: 0.9987 - accuracy: 1.0580e-04 - val_loss: -3.7415e-04 - val_crf_viterbi_accuracy: 0.9987 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99866 to 0.99870, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: -0.0016 - crf_viterbi_accuracy: 0.9989 - accuracy: 1.0580e-04 - val_loss: -8.5485e-04 - val_crf_viterbi_accuracy: 0.9989 - val_accuracy: 0.9989\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.99870 to 0.99885, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 13/40\n",
            "46502/46502 [==============================] - 340s 7ms/step - loss: -0.0024 - crf_viterbi_accuracy: 0.9990 - accuracy: 1.0580e-04 - val_loss: -0.0013 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.99885 to 0.99896, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 14/40\n",
            "46502/46502 [==============================] - 346s 7ms/step - loss: -0.0031 - crf_viterbi_accuracy: 0.9991 - accuracy: 1.0580e-04 - val_loss: -0.0018 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.99896 to 0.99902, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 15/40\n",
            "46502/46502 [==============================] - 345s 7ms/step - loss: -0.0037 - crf_viterbi_accuracy: 0.9992 - accuracy: 1.0580e-04 - val_loss: -0.0023 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.99902 to 0.99906, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 16/40\n",
            "46502/46502 [==============================] - 340s 7ms/step - loss: -0.0043 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.0580e-04 - val_loss: -0.0026 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99906\n",
            "Epoch 17/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: -0.0048 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.0580e-04 - val_loss: -0.0030 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99906\n",
            "Epoch 18/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: -0.0053 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0580e-04 - val_loss: -0.0034 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.99906 to 0.99908, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 19/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0057 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0580e-04 - val_loss: -0.0037 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.99908 to 0.99911, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 20/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0062 - crf_viterbi_accuracy: 0.9994 - accuracy: 1.0580e-04 - val_loss: -0.0042 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.99911 to 0.99912, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 21/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: -0.0066 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0580e-04 - val_loss: -0.0045 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99912\n",
            "Epoch 22/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: -0.0070 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0580e-04 - val_loss: -0.0047 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.99912 to 0.99912, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 23/40\n",
            "46502/46502 [==============================] - 337s 7ms/step - loss: -0.0074 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.0580e-04 - val_loss: -0.0051 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99912\n",
            "Epoch 24/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: -0.0078 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0580e-04 - val_loss: -0.0053 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99912\n",
            "Epoch 25/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0083 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0580e-04 - val_loss: -0.0056 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99912\n",
            "Epoch 26/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0086 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0580e-04 - val_loss: -0.0060 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99912\n",
            "Epoch 27/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0090 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0580e-04 - val_loss: -0.0064 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99912\n",
            "Epoch 28/40\n",
            "46502/46502 [==============================] - 340s 7ms/step - loss: -0.0094 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.0580e-04 - val_loss: -0.0066 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99912\n",
            "Epoch 29/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0098 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0069 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.99912 to 0.99913, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 30/40\n",
            "46502/46502 [==============================] - 340s 7ms/step - loss: -0.0102 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0074 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99913\n",
            "Epoch 31/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: -0.0105 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0077 - val_crf_viterbi_accuracy: 0.9990 - val_accuracy: 0.9990\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99913\n",
            "Epoch 32/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0109 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0081 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99913\n",
            "Epoch 33/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0112 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0083 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99913\n",
            "Epoch 34/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0117 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0086 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99913\n",
            "Epoch 35/40\n",
            "46502/46502 [==============================] - 338s 7ms/step - loss: -0.0120 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0089 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99913\n",
            "Epoch 36/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0124 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0093 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99913\n",
            "Epoch 37/40\n",
            "46502/46502 [==============================] - 340s 7ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0096 - val_crf_viterbi_accuracy: 0.9992 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.99913 to 0.99914, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 38/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0131 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.0580e-04 - val_loss: -0.0100 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99914\n",
            "Epoch 39/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0135 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.0580e-04 - val_loss: -0.0103 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99914\n",
            "Epoch 40/40\n",
            "46502/46502 [==============================] - 339s 7ms/step - loss: -0.0138 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.0580e-04 - val_loss: -0.0107 - val_crf_viterbi_accuracy: 0.9991 - val_accuracy: 0.9991\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8s57YOWCP5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a8e8819-18b4-4094-a77f-f11d30ce744d"
      },
      "source": [
        "# Fit the best model with train2 data\n",
        "history = model.fit(X_train2, np.array(y_train2), batch_size=256, epochs=40, validation_data=(X_dev, np.array(y_dev)), verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 27810 samples, validate on 20655 samples\n",
            "Epoch 1/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0124 - crf_viterbi_accuracy: 0.9993 - accuracy: 1.2218e-04 - val_loss: -0.0137 - val_crf_viterbi_accuracy: 0.9996 - val_accuracy: 0.9996\n",
            "\n",
            "Epoch 00001: val_accuracy improved from 0.99914 to 0.99963, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 2/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0134 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2218e-04 - val_loss: -0.0140 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.99963 to 0.99966, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 3/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0139 - crf_viterbi_accuracy: 0.9995 - accuracy: 1.2218e-04 - val_loss: -0.0143 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.99966 to 0.99967, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 4/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0142 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2218e-04 - val_loss: -0.0144 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.99967 to 0.99968, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 5/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0146 - crf_viterbi_accuracy: 0.9996 - accuracy: 1.2218e-04 - val_loss: -0.0146 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.99968\n",
            "Epoch 6/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0149 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0148 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.99968\n",
            "Epoch 7/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0152 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0150 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99968 to 0.99968, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 8/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0154 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0152 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.99968\n",
            "Epoch 9/40\n",
            "27810/27810 [==============================] - 221s 8ms/step - loss: -0.0157 - crf_viterbi_accuracy: 0.9997 - accuracy: 1.2218e-04 - val_loss: -0.0153 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99968 to 0.99969, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 10/40\n",
            "27810/27810 [==============================] - 228s 8ms/step - loss: -0.0159 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0156 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.99969 to 0.99969, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 11/40\n",
            "27810/27810 [==============================] - 227s 8ms/step - loss: -0.0162 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0158 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99969 to 0.99969, saving model to ner-bi-lstm-td-model-1.00.hdf5\n",
            "Epoch 12/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0164 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0160 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99969\n",
            "Epoch 13/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0166 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0161 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99969\n",
            "Epoch 14/40\n",
            "27810/27810 [==============================] - 226s 8ms/step - loss: -0.0169 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0163 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99969\n",
            "Epoch 15/40\n",
            "27810/27810 [==============================] - 232s 8ms/step - loss: -0.0171 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0165 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.99969\n",
            "Epoch 16/40\n",
            "27810/27810 [==============================] - 224s 8ms/step - loss: -0.0173 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0167 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99969\n",
            "Epoch 17/40\n",
            "27810/27810 [==============================] - 221s 8ms/step - loss: -0.0175 - crf_viterbi_accuracy: 0.9998 - accuracy: 1.2218e-04 - val_loss: -0.0168 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99969\n",
            "Epoch 18/40\n",
            "27810/27810 [==============================] - 225s 8ms/step - loss: -0.0177 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0170 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99969\n",
            "Epoch 19/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0180 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0172 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99969\n",
            "Epoch 20/40\n",
            "27810/27810 [==============================] - 220s 8ms/step - loss: -0.0182 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0174 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99969\n",
            "Epoch 21/40\n",
            "27810/27810 [==============================] - 221s 8ms/step - loss: -0.0184 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0175 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99969\n",
            "Epoch 22/40\n",
            "27810/27810 [==============================] - 221s 8ms/step - loss: -0.0186 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0177 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99969\n",
            "Epoch 23/40\n",
            "27810/27810 [==============================] - 222s 8ms/step - loss: -0.0188 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0180 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.99969\n",
            "Epoch 24/40\n",
            "27810/27810 [==============================] - 229s 8ms/step - loss: -0.0190 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0181 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.99969\n",
            "Epoch 25/40\n",
            "27810/27810 [==============================] - 232s 8ms/step - loss: -0.0192 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0183 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99969\n",
            "Epoch 26/40\n",
            "27810/27810 [==============================] - 225s 8ms/step - loss: -0.0194 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0185 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99969\n",
            "Epoch 27/40\n",
            "27810/27810 [==============================] - 220s 8ms/step - loss: -0.0196 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0187 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.99969\n",
            "Epoch 28/40\n",
            "27810/27810 [==============================] - 221s 8ms/step - loss: -0.0198 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0188 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99969\n",
            "Epoch 29/40\n",
            "27810/27810 [==============================] - 219s 8ms/step - loss: -0.0200 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0190 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99969\n",
            "Epoch 30/40\n",
            "27810/27810 [==============================] - 220s 8ms/step - loss: -0.0203 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0192 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99969\n",
            "Epoch 31/40\n",
            "27810/27810 [==============================] - 227s 8ms/step - loss: -0.0205 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0194 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99969\n",
            "Epoch 32/40\n",
            "27810/27810 [==============================] - 220s 8ms/step - loss: -0.0206 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0196 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99969\n",
            "Epoch 33/40\n",
            "27810/27810 [==============================] - 219s 8ms/step - loss: -0.0209 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0198 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99969\n",
            "Epoch 34/40\n",
            "27810/27810 [==============================] - 223s 8ms/step - loss: -0.0211 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0200 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99969\n",
            "Epoch 35/40\n",
            "27810/27810 [==============================] - 224s 8ms/step - loss: -0.0213 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0202 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99969\n",
            "Epoch 36/40\n",
            "27810/27810 [==============================] - 224s 8ms/step - loss: -0.0215 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0204 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99969\n",
            "Epoch 37/40\n",
            "27810/27810 [==============================] - 219s 8ms/step - loss: -0.0217 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0205 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99969\n",
            "Epoch 38/40\n",
            "27810/27810 [==============================] - 226s 8ms/step - loss: -0.0219 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0207 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99969\n",
            "Epoch 39/40\n",
            "27810/27810 [==============================] - 228s 8ms/step - loss: -0.0221 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0209 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99969\n",
            "Epoch 40/40\n",
            "27810/27810 [==============================] - 227s 8ms/step - loss: -0.0223 - crf_viterbi_accuracy: 0.9999 - accuracy: 1.2218e-04 - val_loss: -0.0211 - val_crf_viterbi_accuracy: 0.9997 - val_accuracy: 0.9997\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2igEEeNLCSJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38baed01-bd9c-46fd-d396-707eedfd4e1d"
      },
      "source": [
        "####PLOTS of loss and accuracy\n",
        "# Plot the graph \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(accuracy) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "####FIT with the TEST data\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag_all[p_i])\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "test_pred = model.predict(X_test, verbose=1)   \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = pred2label(y_test)\n",
        "\n",
        "#####REPORT of the fit\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
        "print(report)\n",
        "\n",
        "###Rest\n",
        "TP = {}\n",
        "TN = {}\n",
        "FP = {}\n",
        "FN = {}\n",
        "for tag in tag2idx_all.keys():\n",
        "    TP[tag] = 0\n",
        "    TN[tag] = 0    \n",
        "    FP[tag] = 0    \n",
        "    FN[tag] = 0    \n",
        "\n",
        "def accumulate_score_by_tag(gt, pred):\n",
        "    \"\"\"\n",
        "    For each tag keep stats\n",
        "    \"\"\"\n",
        "    if gt == pred:\n",
        "        TP[gt] += 1\n",
        "    elif gt != 'O' and pred == 'O':\n",
        "        FN[gt] +=1\n",
        "    elif gt == 'O' and pred != 'O':\n",
        "        FP[gt] += 1\n",
        "    else:\n",
        "        TN[gt] += 1\n",
        "\n",
        "for i, sentence in enumerate(X_test):\n",
        "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
        "    gt = np.argmax(y_test[0], axis=-1)\n",
        "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
        "        accumulate_score_by_tag(idx2tag_all[gt[idx]],tags_all[pred])\n",
        "\n",
        "for tag in tag2idx_all.keys():\n",
        "    print(f'tag:{tag}')    \n",
        "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
        "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20625/20625 [==============================] - 121s 6ms/step\n",
            "F1-score: 86.9%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-diap       0.92      0.89      0.90       878\n",
            "      B-fndg       0.88      0.87      0.88      2971\n",
            "      B-lbpr       0.93      0.92      0.92       443\n",
            "      B-lbtr       0.70      0.53      0.60        59\n",
            "      I-diap       0.91      0.83      0.87       470\n",
            "      I-fndg       0.84      0.81      0.83      2520\n",
            "      I-lbpr       0.83      0.87      0.85       208\n",
            "      I-lbtr       0.74      0.51      0.61        72\n",
            "           O       1.00      1.00      1.00   5643629\n",
            "\n",
            "    accuracy                           1.00   5651250\n",
            "   macro avg       0.86      0.80      0.83   5651250\n",
            "weighted avg       1.00      1.00      1.00   5651250\n",
            "\n",
            "tag:I-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n",
            "tag:O\n",
            "\t TN:         0\tFP:     41250\n",
            "\t FN:         0\tTP:   5568750\n",
            "tag:B-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-lbtr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-diap\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:I-lbpr\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:         0\n",
            "tag:B-fndg\n",
            "\t TN:         0\tFP:         0\n",
            "\t FN:         0\tTP:     20625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzoO5EfoCTyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "train.to_csv('train.csv')\n",
        "dev.to_csv('dev.csv')\n",
        "test.to_csv('test.csv')\n",
        "train2.to_csv('train2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T67xsU8CWdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_unstructured=pd.DataFrame({'Test Tag':test_labels,'Predicted Tag':pred_labels})\n",
        "result_unstructured.to_csv('result_unstructured.csv')\n",
        "\n",
        "test_tag_temp01=[[tag2idx_all[w[1]] for w in s] for s in sentences_test]\n",
        "test_tag_ind01=[]\n",
        "for i in range(len(test_tag_temp01)):\n",
        "  test_tag_ind01.append(len(test_tag_temp01[i]))\n",
        "\n",
        "predicted_tag_temp01=[]\n",
        "for i in range(len(pred_labels)):\n",
        "  predicted_tag_temp01.extend(pred_labels[i][:test_tag_ind01[i]])\n",
        "\n",
        "result=test.assign(predicted_tag=predicted_tag_temp01)\n",
        "result.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdYaMYAHCYvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}